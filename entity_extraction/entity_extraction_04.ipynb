{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import spacy \n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - mock module reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  module_code          id                                            message  \\\n",
      "0    ACC1701X  6472570545   Taken in AY23/24 Semester 2. Lecturer: Prof D...   \n",
      "1    ACC1701X  6467819412   Taken in AY23/24 Semester 2. Lecturer: Prof D...   \n",
      "2    ACC1701X  6452830983   ACC1701X Lecturer: Adjunct Assoc. Prof. Deon ...   \n",
      "3    ACC1701X  5896942778   Taken in AY 21/22 Sem 2, review at: <a href=\"...   \n",
      "4    ACC1701X  5889427965   Taken in AY19/20 Sem 2 Lecturer: Prof Winston...   \n",
      "\n",
      "            created_at  likes  dislikes  \n",
      "0  2024-06-03T01:36:26      0         0  \n",
      "1  2024-05-27T13:10:04      0         0  \n",
      "2  2024-05-07T04:48:19      0         0  \n",
      "3  2022-06-24T09:55:49      0         0  \n",
      "4  2022-06-16T10:03:57      0         0  \n"
     ]
    }
   ],
   "source": [
    "module_review_path = '../04 - mock_module_reviews.csv'\n",
    "module_review = pd.read_csv(module_review_path)\n",
    "\n",
    "print(module_review.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load spacy model for NER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extarct module entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  module_code module_entities\n",
      "0    ACC1701X      [ACC1701X]\n",
      "1    ACC1701X      [ACC1701X]\n",
      "2    ACC1701X      [ACC1701X]\n",
      "3    ACC1701X      [ACC1701X]\n",
      "4    ACC1701X      [ACC1701X]\n"
     ]
    }
   ],
   "source": [
    "def extract_module_entities(module_code):\n",
    "    # Ensure the input is a string and not empty\n",
    "    if isinstance(module_code, str) and module_code.strip():\n",
    "        return [(module_code)]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Apply the function to extract module entities from the 'module_code' column\n",
    "module_review['module_entities'] = module_review['module_code'].apply(lambda x: extract_module_entities(x))\n",
    "\n",
    "# Display the DataFrame with extracted module entities\n",
    "print(module_review[['module_code', 'module_entities']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with links in \"message\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'message' contains 'href' (indicating links)\n",
    "module_review = module_review[~module_review['message'].str.contains('href', na=False, case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracrt skills and staff entities from the \"message\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             message  \\\n",
      "0   Taken in AY23/24 Semester 2. Lecturer: Prof D...   \n",
      "1   Taken in AY23/24 Semester 2. Lecturer: Prof D...   \n",
      "2   ACC1701X Lecturer: Adjunct Assoc. Prof. Deon ...   \n",
      "4   Taken in AY19/20 Sem 2 Lecturer: Prof Winston...   \n",
      "5   Lecturer: Prof Charles Shi Tutor: Mr Philip T...   \n",
      "\n",
      "                      skills_entities             staff_entities  \n",
      "0                                  []                         []  \n",
      "1  [FSA, COGS, DuPont Framework, VAT]                [Prof Chan]  \n",
      "2        [the Very Good to Excellent]  [Prof Winston, Prof Deon]  \n",
      "4                           [ACC/FIN]                         []  \n",
      "5                                  []                         []  \n"
     ]
    }
   ],
   "source": [
    "def extract_skills_and_staff(text, module_entities, all_module_codes):\n",
    "    if isinstance(text, str):  # Ensure the text is a string\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Initialize empty lists for skills and staff\n",
    "        skills = []\n",
    "        staff = []\n",
    "\n",
    "        # Define keywords to exclude non-skill entities\n",
    "        exclude_keywords = {'lecture', 'tutorial', 'midterm', 'mid-term', 'finals', 'quiz', 'module', 'review', 'project', 'assessment', 'maq', 'essay', 'report',\n",
    "                            'mission', 'assignment', 'group', 'attendance', 'elearning', 'course', 'mcq', 'participation', 'exam', 'grade', 'workload', 'presentation', \n",
    "                            'project', 'ca', 'ca1', 'ca2', 'semester', 'sem', 'qna', 'syllabus', 'pyp', 'exam', 'practical', 'pe', 'quest','content', 'coursemology', 'academy'}\n",
    "\n",
    "        # Add a set of non-skill words (like exclamations, etc.)\n",
    "        stopwords = {'awesome', 'hahaha', 'haha', 'lol', 'cool', 'wow', 'excellent'}\n",
    "\n",
    "        # Convert exclude keywords and stopwords to lowercase\n",
    "        exclude_keywords = {keyword.lower() for keyword in exclude_keywords}\n",
    "        stopwords = {word.lower() for word in stopwords}\n",
    "\n",
    "        # Convert exclude keywords into regular expressions for hyphen and space \n",
    "        exclude_patterns = [r'(?i)\\b' + re.escape(keyword) + r'[-\\s]?\\b' for keyword in exclude_keywords]\n",
    "\n",
    "        # Regular expression pattern to remove grades (e.g., A+, B-, C)\n",
    "        grade_pattern = re.compile(r'\\b[A-F][+-]?\\b|\\bS/U\\b|\\bCS\\b|\\bCU\\b', re.IGNORECASE)\n",
    "\n",
    "        # Enhanced regex pattern to capture staff names following titles like 'Prof', 'Dr', 'Lecturer', 'Tutor', and \"Prof-Name\", \"Prof:Name vice versa\"\n",
    "        staff_pattern = re.compile(r'\\b(Prof|Dr|Lecturer|Tutor|Instructor)\\s+[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?', re.IGNORECASE)\n",
    "\n",
    "        # Regular expression pattern to match common name formats (e.g., \"Firstname Lastname\")\n",
    "        name_pattern = re.compile(r'\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?\\b')\n",
    "\n",
    "        # Process each entity in the text\n",
    "        for ent in doc.ents:\n",
    "            # Convert entity text to lowercase for case-insensitive comparison\n",
    "            entity_text_lower = ent.text.lower()\n",
    "\n",
    "            # Check if the entity is related to staff (e.g., names with titles)\n",
    "            match = staff_pattern.search(ent.text)\n",
    "            if match:\n",
    "                # Extract the matched staff names (can handle multiple names like 'Robert Kamei, Magdeline Ng')\n",
    "                staff_name = match.group(0)\n",
    "                staff.append(staff_name.strip())\n",
    "            \n",
    "            # Exclude names of people from the skills_entities using the 'PERSON' label or matching name patterns\n",
    "            elif ent.label_ == 'PERSON' or name_pattern.match(ent.text):\n",
    "                continue  # Skip entities labeled as a person or that look like names\n",
    "\n",
    "            # Otherwise, classify it as a skill if it's not part of the exclude list\n",
    "            elif ent.label_ in ['ORG','PRODUCT', 'SKILL', 'WORK_OF_ART', 'LANGUAGE'] :\n",
    "                # Ensure the entity is not in the exclude list using regex for whole word matching\n",
    "                if (not any(re.search(pattern, entity_text_lower) for pattern in exclude_patterns) \n",
    "                    and not grade_pattern.search(ent.text)\n",
    "                    and ent.text.lower() not in stopwords\n",
    "                    and ent.text.lower() not in [code.lower() for code in all_module_codes]):  # Case-insensitive comparison for module codes\n",
    "                    skills.append(ent.text)\n",
    "\n",
    "        # Remove any module codes (from the entire dataset) from the skills list (case-insensitive comparison)\n",
    "        skills = [skill for skill in skills if skill.lower() not in map(str.lower, all_module_codes)]\n",
    "\n",
    "        # Remove duplicate skills within the same row by converting to set and back to list\n",
    "        skills = list(set(skills))\n",
    "\n",
    "        # Convert list to set and back to list to remove duplicated staff names \n",
    "        staff = list(set(staff))  \n",
    "\n",
    "        return skills, staff\n",
    "    \n",
    "# Gather all unique module codes from the entire dataset\n",
    "all_module_codes = set(module_review['module_code'].str.lower().unique())\n",
    "\n",
    "# Assuming 'message' is the column with reviews for modules\n",
    "module_review[['skills_entities', 'staff_entities']] = module_review.apply(\n",
    "    lambda row: pd.Series(extract_skills_and_staff(row['message'], row['module_entities'], all_module_codes)), axis=1)\n",
    "\n",
    "\n",
    "# Display the DataFrame with the extracted skills\n",
    "print(module_review[['message', 'skills_entities', 'staff_entities']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save updated DF to a new CSV File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_review.to_csv('mock_module_reviews_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
