{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity and Relationship Extractions function\n",
    "\n",
    "- argument to be just the original csv file path\n",
    "- if any column names is in the list of column names then we carry out the functions below\n",
    "- one function for entity extraction (exlcuding module info and review csv)\n",
    "- one function for relationship extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: 05 - mock_venue_info_extracted.csv\n",
      "       Room      Day Class No  Start Time  End Time  \\\n",
      "0  AS1-0213  Tuesday      W25        1400      1600   \n",
      "1  AS1-0213  Tuesday      W28        1600      1800   \n",
      "2  AS1-0213  Tuesday      E07        1000      1200   \n",
      "3  AS1-0213  Tuesday      D11        1200      1400   \n",
      "4  AS1-0213  Tuesday      D09        1000      1200   \n",
      "\n",
      "                                    Weeks lesson_type  size module_code  \\\n",
      "0  2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13    Tutorial    20     HSH1000   \n",
      "1  2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13    Tutorial    20     HSH1000   \n",
      "2                         4, 6, 8, 10, 12    Tutorial    20     HSS1000   \n",
      "3                          3, 5, 7, 9, 11    Tutorial    20     HSS1000   \n",
      "4                          3, 5, 7, 9, 11    Tutorial    20     HSS1000   \n",
      "\n",
      "       module_entities relationships  \n",
      "0  [(HSH1000, MODULE)]            []  \n",
      "1  [(HSH1000, MODULE)]            []  \n",
      "2  [(HSS1000, MODULE)]            []  \n",
      "3  [(HSS1000, MODULE)]            []  \n",
      "4  [(HSS1000, MODULE)]            []  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast \n",
    "import re\n",
    "import spacy\n",
    "import os \n",
    "\n",
    "# Load your spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_entities_rs(csv_file_path): \n",
    "\n",
    "    # Predefined entity columns and their corresponding new column names for entity extraction \n",
    "    target_cols = ['Student_Name', 'Faculties', 'Degree', 'Major', 'Module', 'module_code', 'moduleCode', 'Skills', 'Staff', \n",
    "                   'Modules_Completed', 'department', 'faculty', 'prerequisite', 'preclusion', 'Employee Name', \n",
    "                   'Department', 'Modules Taught', 'Title', 'Job Title', 'Tech Skills', 'university',\n",
    "                   'school', 'degree', 'description', 'message'] \n",
    "\n",
    "    new_entity_cols = {\n",
    "        'Student_Name': ('student_entities', 'STUDENT'),\n",
    "        'Degree': ('degree_entities', 'DEGREE'),\n",
    "        'degree': ('degree_entities', 'DEGREE'),\n",
    "        'Major': ('major_entities', 'MAJOR'),\n",
    "        'Module': ('module_entities', 'MODULE'),\n",
    "        'Modules_Completed': ('module_entities', 'MODULE'),\n",
    "        'module_code': ('module_entities', 'MODULE'),\n",
    "        'moduleCode': ('module_entities', 'MODULE'),\n",
    "        'Modules Taught': ('module_entities', 'MODULE'),\n",
    "        'prerequisite': ('prerequisite_entities', 'PREREQUISITEGROUP'),\n",
    "        'preclusion': ('preclusion_entities', 'PRECLUSIONGROUP'),\n",
    "        'Skills': ('skill_entities', 'SKILL'),\n",
    "        'Tech Skill': ('skill_entities', 'SKILL'),\n",
    "        'Staff': ('staff_entities', 'STAFF'),\n",
    "        'Employee Name': ('staff_entities', 'STAFF'),\n",
    "        'department': ('department_entities', 'DEPARTMENT'), \n",
    "        'Department': ('department_entities', 'DEPARTMENT'), \n",
    "        'Faculties': ('faculty_entities', 'FACULTY'),\n",
    "        'faculty': ('faculty_entities', 'FACULTY'),\n",
    "        'school': ('faculty_entities', 'FACULTY'),\n",
    "        'Title': ('job_entities', 'JOB'),\n",
    "        'Job Title': ('job_entities', 'JOB'),\n",
    "        'university': ('university_entities', 'UNIVERSITY')\n",
    "    }\n",
    "\n",
    "    # Relationship mappings\n",
    "    relationship_mappings = {\n",
    "        ('student_entities', 'faculty_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"STUDYING_UNDER\"},\n",
    "        ('student_entities', 'major_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"MAJOR\", \"relationship_type\": \"MAJOR_IN\"},\n",
    "        ('student_entities', 'module_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"MODULE\", \"relationship_type\": \"COMPLETED\"},\n",
    "        ('module_entities', 'department_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"BELONGS_TO\"},\n",
    "        ('module_entities', 'prerequisite_entities', 'MUST_HAVE_TAKEN_ONE_OF'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"MUST_HAVE_TAKEN_ONE_OF\"},\n",
    "        ('module_entities', 'preclusion_entities', 'MUST_NOT_HAVE_TAKEN_ONE_OF'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"MUST_NOT_HAVE_TAKEN_ONE_OF\"},\n",
    "        ('module_entities', 'prerequisite_entities', 'INCLUDED_AS_PREREQUISITE'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"INCLUDED_AS_PREREQUISITE\"},\n",
    "        ('module_entities', 'preclusion_entities', 'INCLUDED_AS_PRECLUSION'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"INCLUDED_AS_PRECLUSION\"},\n",
    "        ('module_entities', 'semester_entities', 'OFFERED_IN'): {\"from_type\": \"MODULE\", \"to_type\": \"SEMESTER\", \"relationship_type\": \"OFFERED_IN\"},\n",
    "        ('module_entities', 'staff_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"STAFF\", \"relationship_type\": \"TAUGHT_BY\"},\n",
    "        ('staff_entities', 'department_entities'): {\"from_type\": \"STAFF\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"EMPLOYED_UNDER\"},\n",
    "        ('department_entities', 'faculty_entities'): {\"from_type\": \"DEPARTMENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"PART_OF\"},\n",
    "        ('job_entities', 'faculty_entities'): {\"from_type\": \"DEPARTMENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"PART_OF\"},\n",
    "        ('major_entities', 'degree_entities'): {\"from_type\": \"MAJOR\", \"to_type\": \"DEGREE\", \"relationship_type\": \"IS_UNDER\"},\n",
    "        ('job_entities', 'skill_entities'): {\"from_type\": \"JOB\", \"to_type\": \"SKILL\", \"relationship_type\": \"REQUIRES\"},\n",
    "        ('module_entities', 'skill_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"SKILL\", \"relationship_type\": \"SKILL_TAUGHT\"},\n",
    "        ## ADDED\n",
    "        ('university_entities', 'degree_entities'): {\"from_type\": \"UNIVERSTITY\", \"to_type\": \"DEGREE\", \"relationship_type\": \"OFFERS\"},\n",
    "\n",
    "    }\n",
    "\n",
    "    # Extract entities function \n",
    "    def extract_entities(csv_file_path):\n",
    "        def parse_entity(x, entity_type):\n",
    "            # Handle dictionary strings e.g. \n",
    "            if isinstance(x, str) and x.startswith('{') and x.endswith('}'):\n",
    "                return ast.literal_eval(x)  # Convert to dictionary\n",
    "            # Handle already existing list \n",
    "            elif isinstance(x, list):\n",
    "                # return [str(item).strip() for item in flatten_list(x)]  \n",
    "                return [(str(item).strip(), entity_type) for item in flatten_list(x)]\n",
    "            # Handle list strings\n",
    "            elif isinstance(x, str) and x.startswith('[') and x.endswith(']'):\n",
    "                try:\n",
    "                    parsed_list = ast.literal_eval(x)  # Convert string representation of list to actual list\n",
    "                    # return [str(item).strip() for item in flatten_list(parsed_list)]\n",
    "                    return [(str(item).strip(), entity_type) for item in flatten_list(parsed_list)]\n",
    "                except (ValueError, SyntaxError):\n",
    "                    # return [x.strip()] \n",
    "                    return [(x.strip(), entity_type)]\n",
    "                \n",
    "            # Handle comma-separated strings\n",
    "            # NEED TO REVISE THIS AS SOME VALUES HAVE COMMA IN ITSELF E.G. COLLEGE OF HUMANITIES, ARTS & SOCIAL SCIENCES \n",
    "            elif pd.notna(x):\n",
    "                # return [str(item).strip() for item in str(x).split(',')]\n",
    "                # return [x.strip()]\n",
    "                return [(x.strip(), entity_type)]\n",
    "            \n",
    "            # Return an empty list for NaN or other invalid entries\n",
    "            return []\n",
    "        \n",
    "        # Helper function to flatten nested lists\n",
    "        def flatten_list(nested_list):\n",
    "            flat_list = []\n",
    "            for i in nested_list:\n",
    "                if isinstance(i, list):\n",
    "                    flat_list.extend(flatten_list(i))\n",
    "                else:\n",
    "                    flat_list.append(i)\n",
    "            return flat_list\n",
    "\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Extract unique skills from the 'Skills' column in a separate CSV\n",
    "        skills_csv_file_path = '../../backend/data/07 - Jobs and relevant skillset (linkedin).csv'\n",
    "        df_skills = pd.read_csv(skills_csv_file_path)\n",
    "        unique_skills = []\n",
    "        \n",
    "        if 'Skills' in df_skills.columns:\n",
    "            # Modified skills parsing\n",
    "            skills_list = []\n",
    "            for skill_text in df_skills[\"Skills\"].dropna():\n",
    "                # Handle the case where skills are comma-separated\n",
    "                if isinstance(skill_text, str):\n",
    "                    # Remove any square brackets if present\n",
    "                    skill_text = skill_text.strip('[]')\n",
    "                    # Split by comma and clean up each skill\n",
    "                    skills = [skill.strip().strip('\"\\'') for skill in skill_text.split(',')]\n",
    "                    skills_list.extend(skills)\n",
    "            \n",
    "            # Clean up skills and remove duplicates\n",
    "            unique_skills = list(set([re.sub(r'\\s\\(.*\\)', '', skill) for skill in skills_list if skill]))\n",
    "\n",
    "            # remove bracketed abbreviations from skills and the space before it\n",
    "            unique_skills = [re.sub(r'\\s\\(.*\\)', '', skill) for skill in unique_skills]\n",
    "\n",
    "            # remove 'Microsoft ' substring before skills\n",
    "            unique_skills = [re.sub(r'Microsoft\\s', '', skill) for skill in unique_skills]\n",
    "\n",
    "        # Function to extract skills\n",
    "        def extract_skills(text):\n",
    "            if not isinstance(text, str):\n",
    "                return []  # Return an empty list if the input is not a valid string\n",
    "            \n",
    "            doc = nlp(text)\n",
    "            skills = [] \n",
    "\n",
    "            # extract skill entities\n",
    "            for skill in unique_skills:\n",
    "                # create a regex pattern with word boundaries around the job title\n",
    "                pattern = r\"\\b\" + re.escape(skill) + r\"\\b\"\n",
    "    \n",
    "                # search for the job title in the text (case-insensitive)\n",
    "                if re.search(pattern, text, re.IGNORECASE):\n",
    "                    skills.append(skill)\n",
    "\n",
    "            return skills\n",
    "\n",
    "        # Function to extract staff names\n",
    "        def extract_staff_names(text):\n",
    "            if isinstance(text, str):\n",
    "                doc = nlp(text)\n",
    "                staff = []\n",
    "\n",
    "                # Regex pattern to capture staff names with titles like 'Prof', 'Dr', 'Lecturer', 'Tutor'\n",
    "                staff_pattern = re.compile(r'\\b(Prof|Professor|Dr|Lecturer|Tutor|Instructor)\\s*[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?', re.IGNORECASE)\n",
    "                \n",
    "                for ent in doc.ents:\n",
    "                    match = staff_pattern.search(ent.text)\n",
    "                    if match:\n",
    "                        staff_name = match.group(0)\n",
    "\n",
    "                        # Exclude unwanted phrases that are falsely detected as staff names\n",
    "                        if not any(word in staff_name.lower() for word in ['tutorial', 'attendance', 'assignment', 'participation', 'ratios', 'draft', 'profile']):\n",
    "                            staff.append(staff_name.strip())\n",
    "\n",
    "                # Remove duplicates in staff\n",
    "                return list(set(staff))  \n",
    "            \n",
    "            return [] \n",
    "\n",
    "        # Extract semester entities\n",
    "        semester_cols = ['semester_01', 'semester_02', 'semester_03', 'semester_04']\n",
    "        if all(col in df.columns for col in semester_cols):\n",
    "            df['semester_entities'] = df.apply(lambda row: [(col, 'SEMESTER') for col in semester_cols if row[col] == 1], axis=1)\n",
    "\n",
    "        # Extract entities using appropriate functions \n",
    "        for col in target_cols:\n",
    "            if col in df.columns:\n",
    "                # new_entity_col = new_entity_cols[col]     \n",
    "                new_entity_col, entity_type = new_entity_cols.get(col, (col, 'UNKNOWN'))  # Default entity type as 'UNKNOWN'  \n",
    "\n",
    "                # If the column is description or message, we apply special extraction\n",
    "                if col in ['description']:\n",
    "                    # df['skill_entities'] = df[col].apply(lambda text: extract_skills(text))\n",
    "                    df['skill_entities'] = df[col].apply(lambda text: [(skill, 'SKILL') for skill in extract_skills(text)])\n",
    "\n",
    "                elif col in ['description', 'message']:\n",
    "                    # df['skill_entities'] = df[col].apply(lambda text: extract_skills(text))\n",
    "                    # df['staff_entities'] = df[col].apply(lambda text: extract_staff_names(text))\n",
    "                    df['skill_entities'] = df[col].apply(lambda text: [(skill, 'SKILL') for skill in extract_skills(text)])\n",
    "                    df['staff_entities'] = df[col].apply(lambda text: [(staff, 'STAFF') for staff in extract_staff_names(text)])\n",
    "\n",
    "                else:\n",
    "                    # Create the new column with extracted entities, using the helper function\n",
    "                    # df[new_entity_col] = df[col].apply(parse_entity)\n",
    "                    df[new_entity_col] = df[col].apply(lambda x: parse_entity(x, entity_type))\n",
    "\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Extract relationships function \n",
    "    def create_dynamic_relationship(df, from_type, from_id_col, to_type, to_id_col, relationship_type, output_col):\n",
    "        # List to store formatted relationship dictionaries for each row\n",
    "        relationship_column = []\n",
    "\n",
    "        # Iterate through each row of the DataFrame\n",
    "        for _, row in df.iterrows():\n",
    "            # Extract the from_id and to_id values from the specified columns\n",
    "            # from_ids = row[from_id_col] if isinstance(row[from_id_col], list) else [row[from_id_col]]\n",
    "            # to_ids = row[to_id_col] if isinstance(row[to_id_col], list) else [row[to_id_col]]\n",
    "            from_ids = [entity[0] for entity in row[from_id_col] if isinstance(entity, tuple)] if isinstance(row[from_id_col], list) else [row[from_id_col]]\n",
    "            to_ids = [entity[0] for entity in row[to_id_col] if isinstance(entity, tuple)] if isinstance(row[to_id_col], list) else [row[to_id_col]]\n",
    "\n",
    "            # Create a list of dictionaries\n",
    "            relationship_dict = [\n",
    "                {\n",
    "                    \"from_type\": from_type,\n",
    "                    \"from_id\": from_id,\n",
    "                    \"to_type\": to_type,\n",
    "                    \"to_id\": to_id,\n",
    "                    \"type\": relationship_type\n",
    "                }\n",
    "                for from_id in from_ids if pd.notna(from_id)\n",
    "                for to_id in to_ids if pd.notna(to_id)  # Only include non-NaN to_id values\n",
    "            ]\n",
    "\n",
    "            # Append the relationship dictionary or an empty list if no valid to_id found\n",
    "            relationship_column.append(relationship_dict if relationship_dict else [])\n",
    "\n",
    "        # Add the relationships as a new column to the DataFrame\n",
    "        df[output_col] = relationship_column\n",
    "        \n",
    "        # Return the updated DataFrame with the new relationships column\n",
    "        return df\n",
    "    \n",
    "    # Step 1: Extract Entities \n",
    "    df = extract_entities(csv_file_path)\n",
    "\n",
    "    # Step 2: Extract Relationships based on predefined mappings \n",
    "    for key, relationship_info in relationship_mappings.items():\n",
    "        if len(key) == 3:\n",
    "            from_col, to_col, rel_key = key\n",
    "        elif len(key) == 2:\n",
    "            from_col, to_col = key\n",
    "            rel_key = ''  # Set rel_key as an empty string or any default value as needed\n",
    "\n",
    "        if from_col in df.columns and to_col in df.columns:\n",
    "            output_col = f\"{from_col}_to_{to_col}_{relationship_info['relationship_type'].lower()}_relationship\"\n",
    "            df = create_dynamic_relationship(\n",
    "                df,\n",
    "                relationship_info['from_type'],\n",
    "                from_col,\n",
    "                relationship_info['to_type'],\n",
    "                to_col,\n",
    "                relationship_info['relationship_type'],\n",
    "                output_col\n",
    "            )\n",
    "\n",
    "    # Combine all relationship columns into one\n",
    "    relationship_columns = [col for col in df.columns if '_relationship' in col]\n",
    "    if relationship_columns:\n",
    "        df['relationships'] = df[relationship_columns].apply(lambda row: [item for sublist in row if isinstance(sublist, list) for item in sublist], axis=1)\n",
    "        # Drop the individual relationship columns if no longer needed\n",
    "        df = df.drop(columns=relationship_columns)\n",
    "    else: \n",
    "        # Set to a list of empty lists for each row\n",
    "        df['relationships'] = [[] for _ in range(len(df))]  \n",
    "\n",
    "    # Step 3: Output final df\n",
    "    return df\n",
    "\n",
    "\n",
    "# Extract from existing cleaned datasets \n",
    "# csv_file_path = '../../backend/data/00 - mock_student_data.csv'\n",
    "# csv_file_path = '../../backend/data/01 - mock_module_info.csv'\n",
    "# csv_file_path = '../../backend/data/02 - mock_department_list.csv'\n",
    "# csv_file_path = '../../backend/data/03 - mock_staff_info.csv'\n",
    "# csv_file_path = '../../backend/data/04 - mock_module_reviews.csv'\n",
    "csv_file_path = '../../backend/data/05 - mock_venue_info.csv'\n",
    "# csv_file_path = '../../backend/data/06 - nus_undergraduate_programmes.csv'\n",
    "# csv_file_path = '../../backend/data/07 - Jobs and relevant skillset (linkedin).csv'\n",
    "# csv_file_path = '../../backend/data/08 - jobs_and_tech (ONET).csv'\n",
    "# csv_file_path = '../../backend/data/09 - jobs_and_skills (ONET).csv'\n",
    "# csv_file_path = '../../backend/data/10 - Graduate Employment Survey.csv'\n",
    "\n",
    "# Extract Entities and Relationships\n",
    "df = extract_entities_rs(csv_file_path)\n",
    "\n",
    "# Extract base name and append '_extracted'\n",
    "base_name, ext = os.path.splitext(os.path.basename(csv_file_path))\n",
    "new_file_name = f\"{base_name}_extracted{ext}\"\n",
    "\n",
    "# Save the DataFrame to the new file\n",
    "df.to_csv(new_file_name, index=False)\n",
    "\n",
    "# Print a success message with the new file name\n",
    "print(f\"Data saved to: {new_file_name}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy PhraseMatcher (faster but shorter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  moduleCode                                title  \\\n",
      "0    ABM5001            Leadership in Biomedicine   \n",
      "1    ABM5002  Advanced Biostatistics for Research   \n",
      "2    ABM5003   Biomedical Innovation & Enterprise   \n",
      "3    ABM5004                     Capstone Project   \n",
      "4    ABM5101                   Applied Immunology   \n",
      "\n",
      "                                         description  moduleCredit  \\\n",
      "0  Leadership is fundamental to the success of in...           2.0   \n",
      "1  This course is served as a concept-based intro...           2.0   \n",
      "2  This course will furnish students with a thoro...           4.0   \n",
      "3  This course encompasses research projects rele...           8.0   \n",
      "4  Advanced immunological applications play impor...           4.0   \n",
      "\n",
      "                   department                       faculty  \\\n",
      "0  NUS Medicine Dean's Office  Yong Loo Lin Sch of Medicine   \n",
      "1  NUS Medicine Dean's Office  Yong Loo Lin Sch of Medicine   \n",
      "2  NUS Medicine Dean's Office  Yong Loo Lin Sch of Medicine   \n",
      "3  NUS Medicine Dean's Office  Yong Loo Lin Sch of Medicine   \n",
      "4  NUS Medicine Dean's Office  Yong Loo Lin Sch of Medicine   \n",
      "\n",
      "  gradingBasisDescription prerequisite preclusion attributes  ... semester_04  \\\n",
      "0                  Graded           []         []        NaN  ...           0   \n",
      "1                  Graded           []         []        NaN  ...           0   \n",
      "2                  Graded           []         []        NaN  ...           0   \n",
      "3                  Graded           []         []        NaN  ...           0   \n",
      "4                  Graded           []         []        NaN  ...           0   \n",
      "\n",
      "   UE                                  semester_entities      module_entities  \\\n",
      "0   0                          [(semester_02, SEMESTER)]  [(ABM5001, MODULE)]   \n",
      "1   0                          [(semester_02, SEMESTER)]  [(ABM5002, MODULE)]   \n",
      "2   0                          [(semester_01, SEMESTER)]  [(ABM5003, MODULE)]   \n",
      "3   0  [(semester_01, SEMESTER), (semester_02, SEMEST...  [(ABM5004, MODULE)]   \n",
      "4   0                          [(semester_01, SEMESTER)]  [(ABM5101, MODULE)]   \n",
      "\n",
      "                          department_entities  \\\n",
      "0  [(NUS Medicine Dean's Office, DEPARTMENT)]   \n",
      "1  [(NUS Medicine Dean's Office, DEPARTMENT)]   \n",
      "2  [(NUS Medicine Dean's Office, DEPARTMENT)]   \n",
      "3  [(NUS Medicine Dean's Office, DEPARTMENT)]   \n",
      "4  [(NUS Medicine Dean's Office, DEPARTMENT)]   \n",
      "\n",
      "                            faculty_entities  prerequisite_entities  \\\n",
      "0  [(Yong Loo Lin Sch of Medicine, FACULTY)]                     []   \n",
      "1  [(Yong Loo Lin Sch of Medicine, FACULTY)]                     []   \n",
      "2  [(Yong Loo Lin Sch of Medicine, FACULTY)]                     []   \n",
      "3  [(Yong Loo Lin Sch of Medicine, FACULTY)]                     []   \n",
      "4  [(Yong Loo Lin Sch of Medicine, FACULTY)]                     []   \n",
      "\n",
      "   preclusion_entities         skill_entities  \\\n",
      "0                   []  [(Leadership, SKILL)]   \n",
      "1                   []                     []   \n",
      "2                   []                     []   \n",
      "3                   []                     []   \n",
      "4                   []                     []   \n",
      "\n",
      "                                       relationships  \n",
      "0  [{'from_type': 'MODULE', 'from_id': 'ABM5001',...  \n",
      "1  [{'from_type': 'MODULE', 'from_id': 'ABM5002',...  \n",
      "2  [{'from_type': 'MODULE', 'from_id': 'ABM5003',...  \n",
      "3  [{'from_type': 'MODULE', 'from_id': 'ABM5004',...  \n",
      "4  [{'from_type': 'MODULE', 'from_id': 'ABM5101',...  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast \n",
    "import re\n",
    "import spacy\n",
    "import os \n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "\n",
    "# Load your spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_entities_rs(csv_file_path): \n",
    "\n",
    "    # Predefined entity columns and their corresponding new column names for entity extraction \n",
    "    target_cols = ['Student_Name', 'Faculties', 'Degree', 'Major', 'Module', 'module_code', 'moduleCode', 'Skills', 'Staff', \n",
    "                   'Modules_Completed', 'department', 'faculty', 'prerequisite', 'preclusion', 'Employee Name', \n",
    "                   'Department', 'Modules Taught', 'Title', 'Job Title', 'Tech Skills', 'university',\n",
    "                   'school', 'degree', 'description', 'message']\n",
    "\n",
    "    new_entity_cols = {\n",
    "        'Student_Name': ('student_entities', 'STUDENT'),\n",
    "        'Degree': ('degree_entities', 'DEGREE'),\n",
    "        'degree': ('degree_entities', 'DEGREE'),\n",
    "        'Major': ('major_entities', 'MAJOR'),\n",
    "        'Module': ('module_entities', 'MODULE'),\n",
    "        'Modules_Completed': ('module_entities', 'MODULE'),\n",
    "        'module_code': ('module_entities', 'MODULE'),\n",
    "        'moduleCode': ('module_entities', 'MODULE'),\n",
    "        'Modules Taught': ('module_entities', 'MODULE'),\n",
    "        'prerequisite': ('prerequisite_entities', 'PREREQUISITEGROUP'),\n",
    "        'preclusion': ('preclusion_entities', 'PRECLUSIONGROUP'),\n",
    "        'Skills': ('skill_entities', 'SKILL'),\n",
    "        'Tech Skill': ('skill_entities', 'SKILL'),\n",
    "        'Staff': ('staff_entities', 'STAFF'),\n",
    "        'Employee Name': ('staff_entities', 'STAFF'),\n",
    "        'department': ('department_entities', 'DEPARTMENT'), \n",
    "        'Department': ('department_entities', 'DEPARTMENT'), \n",
    "        'Faculties': ('faculty_entities', 'FACULTY'),\n",
    "        'faculty': ('faculty_entities', 'FACULTY'),\n",
    "        'school': ('faculty_entities', 'FACULTY'),\n",
    "        'Title': ('job_entities', 'JOB'),\n",
    "        'Job Title': ('job_entities', 'JOB'),\n",
    "        'university': ('university_entities', 'UNIVERSITY'),\n",
    "    }\n",
    "\n",
    "    # Relationship mappings\n",
    "    relationship_mappings = {\n",
    "        ('student_entities', 'faculty_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"STUDYING_UNDER\"},\n",
    "        ('student_entities', 'major_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"MAJOR\", \"relationship_type\": \"MAJOR_IN\"},\n",
    "        ('student_entities', 'module_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"MODULE\", \"relationship_type\": \"COMPLETED\"},\n",
    "        ('module_entities', 'department_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"BELONGS_TO\"},\n",
    "        ('module_entities', 'prerequisite_entities', 'MUST_HAVE_TAKEN_ONE_OF'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"MUST_HAVE_TAKEN_ONE_OF\"},\n",
    "        ('module_entities', 'preclusion_entities', 'MUST_NOT_HAVE_TAKEN_ONE_OF'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"MUST_NOT_HAVE_TAKEN_ONE_OF\"},\n",
    "\n",
    "        ('module_entities', 'prerequisite_entities', 'INCLUDED_AS_PREREQUISITE'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"INCLUDED_AS_PREREQUISITE\"},\n",
    "        ('module_entities', 'preclusion_entities', 'INCLUDED_AS_PRECLUSION'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"INCLUDED_AS_PRECLUSION\"},\n",
    "        ('module_entities', 'semester_entities', 'OFFERED_IN'): {\"from_type\": \"MODULE\", \"to_type\": \"SEMESTER\", \"relationship_type\": \"OFFERED_IN\"},\n",
    "        #SEMESTER (can be excluded as this is exception for module info?)\n",
    "        ('module_entities', 'staff_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"STAFF\", \"relationship_type\": \"TAUGHT_BY\"},\n",
    "        ('staff_entities', 'department_entities'): {\"from_type\": \"STAFF\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"EMPLOYED_UNDER\"},\n",
    "        ('department_entities', 'faculty_entities'): {\"from_type\": \"DEPARTMENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"PART_OF\"},\n",
    "        ('job_entities', 'faculty_entities'): {\"from_type\": \"DEPARTMENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"PART_OF\"},\n",
    "        ('major_entities', 'degree_entities'): {\"from_type\": \"MAJOR\", \"to_type\": \"DEGREE\", \"relationship_type\": \"IS_UNDER\"},\n",
    "        ('job_entities', 'skill_entities'): {\"from_type\": \"JOB\", \"to_type\": \"SKILL\", \"relationship_type\": \"REQUIRES\"},\n",
    "        ('module_entities', 'skill_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"SKILL\", \"relationship_type\": \"SKILL_TAUGHT\"},\n",
    "        ## ADDED\n",
    "        ('university_entities', 'degree_entities'): {\"from_type\": \"UNIVERSTITY\", \"to_type\": \"DEGREE\", \"relationship_type\": \"OFFERS\"},\n",
    "\n",
    "    }\n",
    "\n",
    "    # Extract entities function \n",
    "    def extract_entities(csv_file_path):\n",
    "        def parse_entity(x, entity_type):\n",
    "            # Handle dictionary strings e.g. \n",
    "            if isinstance(x, str) and x.startswith('{') and x.endswith('}'):\n",
    "                return ast.literal_eval(x)  # Convert to dictionary\n",
    "            # Handle already existing list \n",
    "            elif isinstance(x, list):\n",
    "                return [(str(item).strip(), entity_type) for item in flatten_list(x)]\n",
    "            # Handle list strings\n",
    "            elif isinstance(x, str) and x.startswith('[') and x.endswith(']'):\n",
    "                try:\n",
    "                    parsed_list = ast.literal_eval(x)  # Convert string representation of list to actual list\n",
    "                    return [(str(item).strip(), entity_type) for item in flatten_list(parsed_list)]\n",
    "                except (ValueError, SyntaxError):\n",
    "                    # return [x.strip()] \n",
    "                    return [(x.strip(), entity_type)]\n",
    "                \n",
    "            # Handle comma-separated strings\n",
    "            # NEED TO REVISE THIS AS SOME VALUES HAVE COMMA IN ITSELF E.G. COLLEGE OF HUMANITIES, ARTS & SOCIAL SCIENCES \n",
    "            elif pd.notna(x):\n",
    "                return [(x.strip(), entity_type)]\n",
    "            \n",
    "            # Return an empty list for NaN or other invalid entries\n",
    "            return []\n",
    "        \n",
    "        # Helper function to flatten nested lists\n",
    "        def flatten_list(nested_list):\n",
    "            flat_list = []\n",
    "            for i in nested_list:\n",
    "                if isinstance(i, list):\n",
    "                    flat_list.extend(flatten_list(i))\n",
    "                else:\n",
    "                    flat_list.append(i)\n",
    "            return flat_list\n",
    "\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Extract unique skills from the 'Skills' column in a separate CSV\n",
    "        skills_csv_file_path = '../../backend/data/07 - Jobs and relevant skillset (linkedin).csv'\n",
    "        df_skills = pd.read_csv(skills_csv_file_path)\n",
    "        unique_skills = []\n",
    "        \n",
    "        if 'Skills' in df_skills.columns:\n",
    "            # Modified skills parsing\n",
    "            skills_list = []\n",
    "            for skill_text in df_skills[\"Skills\"].dropna():\n",
    "                # Handle the case where skills are comma-separated\n",
    "                if isinstance(skill_text, str):\n",
    "                    # Remove any square brackets if present\n",
    "                    skill_text = skill_text.strip('[]')\n",
    "                    # Split by comma and clean up each skill\n",
    "                    skills = [skill.strip().strip('\"\\'') for skill in skill_text.split(',')]\n",
    "                    skills_list.extend(skills)\n",
    "            \n",
    "            # Clean up skills and remove duplicates\n",
    "            unique_skills = list(set([re.sub(r'\\s\\(.*\\)', '', skill) for skill in skills_list if skill]))\n",
    "\n",
    "            # remove bracketed abbreviations from skills and the space before it\n",
    "            unique_skills = [re.sub(r'\\s\\(.*\\)', '', skill) for skill in unique_skills]\n",
    "\n",
    "            # remove 'Microsoft ' substring before skills\n",
    "            unique_skills = [re.sub(r'Microsoft\\s', '', skill) for skill in unique_skills]\n",
    "        \n",
    "        # Initialize the matcher with the nlp vocabulary\n",
    "        matcher = PhraseMatcher(nlp.vocab)\n",
    "        patterns = [nlp(skill) for skill in unique_skills]  # Assuming unique_skills is defined globally\n",
    "        matcher.add(\"SKILLS\", patterns)\n",
    "\n",
    "\n",
    "        # Function to extract skills using PhraseMatcher\n",
    "        def extract_skills_using_phrasematcher(text, matcher):\n",
    "            if not isinstance(text, str):\n",
    "                return []  # Return empty list if not a valid string\n",
    "            doc = nlp(text)\n",
    "            matches = matcher(doc)\n",
    "            skills = [doc[start:end].text for match_id, start, end in matches]\n",
    "            return list(set(skills))  # Remove duplicates\n",
    "\n",
    "        # Function to extract staff names\n",
    "        def extract_staff_names(text):\n",
    "            if isinstance(text, str):\n",
    "                doc = nlp(text)\n",
    "                staff = []\n",
    "\n",
    "                # Regex pattern to capture staff names with titles like 'Prof', 'Dr', 'Lecturer', 'Tutor'\n",
    "                staff_pattern = re.compile(r'\\b(Prof|Professor|Dr|Lecturer|Tutor|Instructor)\\s*[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?', re.IGNORECASE)\n",
    "                \n",
    "                for ent in doc.ents:\n",
    "                    match = staff_pattern.search(ent.text)\n",
    "                    if match:\n",
    "                        staff_name = match.group(0)\n",
    "\n",
    "                        # Exclude unwanted phrases that are falsely detected as staff names\n",
    "                        if not any(word in staff_name.lower() for word in ['tutorial', 'attendance', 'assignment', 'participation', 'ratios', 'draft', 'profile']):\n",
    "                            staff.append(staff_name.strip())\n",
    "\n",
    "                # Remove duplicates in staff\n",
    "                return list(set(staff))  \n",
    "            \n",
    "            return [] \n",
    "\n",
    "        # Extract semester entities\n",
    "        semester_cols = ['semester_01', 'semester_02', 'semester_03', 'semester_04']\n",
    "        if all(col in df.columns for col in semester_cols):\n",
    "            df['semester_entities'] = df.apply(lambda row: [(col, 'SEMESTER') for col in semester_cols if row[col] == 1], axis=1)\n",
    "\n",
    "        # Extract entities using appropriate functions \n",
    "        for col in target_cols:\n",
    "            if col in df.columns:\n",
    "                # new_entity_col = new_entity_cols[col]     \n",
    "                new_entity_col, entity_type = new_entity_cols.get(col, (col, 'UNKNOWN'))  # Default entity type as 'UNKNOWN'  \n",
    "\n",
    "                # If the column is description or message, we apply special extraction\n",
    "                if col in ['description']:\n",
    "                    df['skill_entities'] = df[col].apply(lambda text: [(skill, 'SKILL') for skill in extract_skills_using_phrasematcher(text, matcher)])\n",
    "\n",
    "                elif col in ['description', 'message']:\n",
    "                    df['skill_entities'] = df[col].apply(lambda text: [(skill, 'SKILL') for skill in extract_skills_using_phrasematcher(text, matcher)])\n",
    "                    df['staff_entities'] = df[col].apply(lambda text: [(staff, 'STAFF') for staff in extract_staff_names(text)])\n",
    "\n",
    "                else:\n",
    "                    # Create the new column with extracted entities, using the helper function\n",
    "                    df[new_entity_col] = df[col].apply(lambda x: parse_entity(x, entity_type))\n",
    "\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Extract relationships function \n",
    "    def create_dynamic_relationship(df, from_type, from_id_col, to_type, to_id_col, relationship_type, output_col):\n",
    "        # List to store formatted relationship dictionaries for each row\n",
    "        relationship_column = []\n",
    "\n",
    "        # Iterate through each row of the DataFrame\n",
    "        for _, row in df.iterrows():\n",
    "            # Extract the from_id and to_id values from the specified columns\n",
    "            from_ids = [entity[0] for entity in row[from_id_col] if isinstance(entity, tuple)] if isinstance(row[from_id_col], list) else [row[from_id_col]]\n",
    "            to_ids = [entity[0] for entity in row[to_id_col] if isinstance(entity, tuple)] if isinstance(row[to_id_col], list) else [row[to_id_col]]\n",
    "\n",
    "            # Create a list of dictionaries\n",
    "            relationship_dict = [\n",
    "                {\n",
    "                    \"from_type\": from_type,\n",
    "                    \"from_id\": from_id,\n",
    "                    \"to_type\": to_type,\n",
    "                    \"to_id\": to_id,\n",
    "                    \"type\": relationship_type\n",
    "                }\n",
    "                for from_id in from_ids if pd.notna(from_id)\n",
    "                for to_id in to_ids if pd.notna(to_id)  # Only include non-NaN to_id values\n",
    "            ]\n",
    "\n",
    "            # Append the relationship dictionary or an empty list if no valid to_id found\n",
    "            relationship_column.append(relationship_dict if relationship_dict else [])\n",
    "\n",
    "        # Add the relationships as a new column to the DataFrame\n",
    "        df[output_col] = relationship_column\n",
    "        \n",
    "        # Return the updated DataFrame with the new relationships column\n",
    "        return df\n",
    "    \n",
    "    # Step 1: Extract Entities \n",
    "    df = extract_entities(csv_file_path)\n",
    "\n",
    "    # Step 2: Extract Relationships based on predefined mappings \n",
    "    for key, relationship_info in relationship_mappings.items():\n",
    "        if len(key) == 3:\n",
    "            from_col, to_col, rel_key = key\n",
    "        elif len(key) == 2:\n",
    "            from_col, to_col = key\n",
    "            rel_key = ''  # Set rel_key as an empty string or any default value as needed\n",
    "\n",
    "        if from_col in df.columns and to_col in df.columns:\n",
    "            output_col = f\"{from_col}_to_{to_col}_{relationship_info['relationship_type'].lower()}_relationship\"\n",
    "            df = create_dynamic_relationship(\n",
    "                df,\n",
    "                relationship_info['from_type'],\n",
    "                from_col,\n",
    "                relationship_info['to_type'],\n",
    "                to_col,\n",
    "                relationship_info['relationship_type'],\n",
    "                output_col\n",
    "            )\n",
    "\n",
    "    # Combine all relationship columns into one\n",
    "    relationship_columns = [col for col in df.columns if '_relationship' in col]\n",
    "    if relationship_columns:\n",
    "        df['relationships'] = df[relationship_columns].apply(lambda row: [item for sublist in row if isinstance(sublist, list) for item in sublist], axis=1)\n",
    "        # Drop the individual relationship columns if no longer needed\n",
    "        df = df.drop(columns=relationship_columns)\n",
    "    else: \n",
    "        # Set to a list of empty lists for each row\n",
    "        df['relationships'] = [[] for _ in range(len(df))]  \n",
    "\n",
    "    # Step 3: Output final df\n",
    "    return df\n",
    "\n",
    "\n",
    "# Extract from existing cleaned datasets \n",
    "# csv_file_path = '../../backend/data/00 - mock_student_data.csv'\n",
    "csv_file_path = '../../backend/data/01 - mock_module_info.csv'\n",
    "# csv_file_path = '../../backend/data/02 - mock_department_list.csv'\n",
    "# csv_file_path = '../../backend/data/03 - mock_staff_info.csv'\n",
    "# csv_file_path = '../../backend/data/04 - mock_module_reviews.csv'\n",
    "# csv_file_path = '../../backend/data/05 - mock_venue_info.csv'\n",
    "# csv_file_path = '../../backend/data/06 - nus_undergraduate_programmes.csv'\n",
    "# csv_file_path = '../../backend/data/07 - Jobs and relevant skillset (linkedin).csv'\n",
    "# csv_file_path = '../../backend/data/08 - jobs_and_tech (ONET).csv'\n",
    "# csv_file_path = '../../backend/data/09 - jobs_and_skills (ONET).csv'\n",
    "# csv_file_path = '../../backend/data/10 - Graduate Employment Survey.csv'\n",
    "\n",
    "# Extract Entities and Relationships\n",
    "df = extract_entities_rs(csv_file_path)\n",
    "\n",
    "# Extract base name and append '_extracted'\n",
    "base_name, ext = os.path.splitext(os.path.basename(csv_file_path))\n",
    "new_file_name = f\"{base_name}_extracted{ext}\"\n",
    "\n",
    "# Save the DataFrame to the new file\n",
    "df.to_csv(new_file_name, index=False)\n",
    "\n",
    "# Print a success message with the new file name\n",
    "print(f\"Data saved to: {new_file_name}\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
