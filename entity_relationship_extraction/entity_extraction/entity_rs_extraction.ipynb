{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity and Relationship Extractions function\n",
    "\n",
    "- argument to be just the original csv file path\n",
    "- if any column names is in the list of column names then we carry out the functions below\n",
    "- one function for entity extraction (exlcuding module info and review csv)\n",
    "- one function for relationship extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast \n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Student_Name Matric_Number       NRIC  Year  \\\n",
      "0      Tracy Lewis     A0216920B  XXXXX506Z     1   \n",
      "1    Andrew Holden     A0225069H  XXXXX799Z     3   \n",
      "2  Phillip Bullock     A0228204E  XXXXX194Z     1   \n",
      "3    Stephen Owens     A0263298Z  XXXXX790Z     1   \n",
      "4   Valerie Rivera     A0200778Y  XXXXX150Z     3   \n",
      "\n",
      "                           Faculties                    Major Second Major  \\\n",
      "0                NUS Business School  Business Administration          NaN   \n",
      "1          YST Conservatory of Music                    Music          NaN   \n",
      "2  College of Design and Engineering   Electrical Engineering          NaN   \n",
      "3                          Dentistry                Dentistry          NaN   \n",
      "4                          Computing       Business Analytics          NaN   \n",
      "\n",
      "                                   Modules_Completed  \\\n",
      "0  ['ACC1701B', 'DMB1202ACC', 'DMB1201MKT', 'MNO1...   \n",
      "1  ['CFA1111A', 'MUA1190', 'MUA2109', 'MUA1172', ...   \n",
      "2  ['ME1102', 'BN1111', 'PF1103', 'CN1101A', 'ID1...   \n",
      "3                                                 []   \n",
      "4  ['CS3236R', 'CS1010', 'CP3209', 'CS1010R', 'IS...   \n",
      "\n",
      "                                              Grades  \\\n",
      "0  {'ACC1701B': 'B', 'DMB1202ACC': 'A', 'DMB1201M...   \n",
      "1  {'CFA1111A': 'F', 'MUA1190': 'A', 'MUA2109': '...   \n",
      "2  {'ME1102': 'F', 'BN1111': 'B-', 'PF1103': 'C+'...   \n",
      "3                                                 {}   \n",
      "4  {'CS3236R': 'A+', 'CS1010': 'A+', 'CP3209': 'A...   \n",
      "\n",
      "               student_entities  \\\n",
      "0      [(Tracy Lewis, STUDENT)]   \n",
      "1    [(Andrew Holden, STUDENT)]   \n",
      "2  [(Phillip Bullock, STUDENT)]   \n",
      "3    [(Stephen Owens, STUDENT)]   \n",
      "4   [(Valerie Rivera, STUDENT)]   \n",
      "\n",
      "                                 faculty_entities  \\\n",
      "0                [(NUS Business School, FACULTY)]   \n",
      "1          [(YST Conservatory of Music, FACULTY)]   \n",
      "2  [(College of Design and Engineering, FACULTY)]   \n",
      "3                          [(Dentistry, FACULTY)]   \n",
      "4                          [(Computing, FACULTY)]   \n",
      "\n",
      "                       major_entities  \\\n",
      "0  [(Business Administration, MAJOR)]   \n",
      "1                    [(Music, MAJOR)]   \n",
      "2   [(Electrical Engineering, MAJOR)]   \n",
      "3                [(Dentistry, MAJOR)]   \n",
      "4       [(Business Analytics, MAJOR)]   \n",
      "\n",
      "                                     module_entities  \\\n",
      "0  [(ACC1701B, MODULE), (DMB1202ACC, MODULE), (DM...   \n",
      "1  [(CFA1111A, MODULE), (MUA1190, MODULE), (MUA21...   \n",
      "2  [(ME1102, MODULE), (BN1111, MODULE), (PF1103, ...   \n",
      "3                                                 []   \n",
      "4  [(CS3236R, MODULE), (CS1010, MODULE), (CP3209,...   \n",
      "\n",
      "                                       relationships  \n",
      "0  [{'from_type': 'STUDENT', 'from_id': 'Tracy Le...  \n",
      "1  [{'from_type': 'STUDENT', 'from_id': 'Andrew H...  \n",
      "2  [{'from_type': 'STUDENT', 'from_id': 'Phillip ...  \n",
      "3  [{'from_type': 'STUDENT', 'from_id': 'Stephen ...  \n",
      "4  [{'from_type': 'STUDENT', 'from_id': 'Valerie ...  \n"
     ]
    }
   ],
   "source": [
    "def extract_entities_rs(csv_file_path): \n",
    "\n",
    "    # Predefined entity columns and their corresponding new column names for entity extraction \n",
    "    target_cols = ['Student_Name', 'Faculties', 'Degree', 'Major', 'Module', 'module_code', 'moduleCode', 'Skills', 'Staff', \n",
    "                   'Modules_Completed', 'department', 'faculty', 'prerequisite', 'preclusion', 'Employee Name', \n",
    "                   'Department', 'Modules Taught', 'Title', 'Job Title', 'Tech Skills', 'university'\n",
    "                   'school', 'degree', 'description', 'message'] # Add any other columns you want to check for\n",
    "    # 'description', 'message']  \n",
    "\n",
    "    new_entity_cols = {\n",
    "        'Student_Name': ('student_entities', 'STUDENT'),\n",
    "        'Degree': ('degree_entities', 'DEGREE'),\n",
    "        'degree': ('degree_entities', 'DEGREE'),\n",
    "        'Major': ('major_entities', 'MAJOR'),\n",
    "        'Module': ('module_entities', 'MODULE'),\n",
    "        'Modules_Completed': ('module_entities', 'MODULE'),\n",
    "        'module_code': ('module_entities', 'MODULE'),\n",
    "        'moduleCode': ('module_entities', 'MODULE'),\n",
    "        'Modules Taught': ('module_entities', 'MODULE'),\n",
    "        'prerequisite': ('prerequisite_entities', 'PREREQUISITEGROUP'),\n",
    "        'preclusion': ('preclusion_entities', 'PRECLUSIONGROUP'),\n",
    "        'Skills': ('skill_entities', 'SKILL'),\n",
    "        'Tech Skills': ('skill_entities', 'SKILL'),\n",
    "        'Staff': ('staff_entities', 'STAFF'),\n",
    "        'Employee Name': ('staff_entities', 'STAFF'),\n",
    "        'department': ('department_entities', 'DEPARTMENT'), \n",
    "        'Department': ('department_entities', 'DEPARTMENT'), \n",
    "        'Faculties': ('faculty_entities', 'FACULTY'),\n",
    "        'faculty': ('faculty_entities', 'FACULTY'),\n",
    "        'school': ('faculty_entities', 'FACULTY'),\n",
    "        'Title': ('job_entities', 'JOB'),\n",
    "        'Job Title': ('job_entities', 'JOB'),\n",
    "        'university': ('university_entities', 'UNIVERSITY'),\n",
    "        # 'description': ('description_entities', 'DESCRIPTION'),\n",
    "        # 'message': ('message_entities', 'MESSAGE')\n",
    "    }\n",
    "\n",
    "    # Relationship mappings\n",
    "    relationship_mappings = {\n",
    "        ('student_entities', 'faculty_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"STUDYING_UNDER\"},\n",
    "        ('student_entities', 'major_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"MAJOR\", \"relationship_type\": \"MAJOR_IN\"},\n",
    "        ('student_entities', 'module_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"MODULE\", \"relationship_type\": \"COMPLETED\"},\n",
    "        ('module_entities', 'department_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"BELONGS_TO\"},\n",
    "        ('module_entities', 'prerequisite_entities', 'MUST_HAVE_TAKEN_ONE_OF'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"MUST_HAVE_TAKEN_ONE_OF\"},\n",
    "        ('module_entities', 'preclusion_entities', 'MUST_NOT_HAVE_TAKEN_ONE_OF'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"MUST_NOT_HAVE_TAKEN_ONE_OF\"},\n",
    "\n",
    "        ('module_entities', 'prerequisite_entities', 'INCLUDED_AS_PREREQUISITE'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"INCLUDED_AS_PREREQUISITE\"},\n",
    "        ('module_entities', 'preclusion_entities', 'INCLUDED_AS_PRECLUSION'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"INCLUDED_AS_PRECLUSION\"},\n",
    "        ('module_entities', 'semester_entities', 'OFFERED_IN'): {\"from_type\": \"MODULE\", \"to_type\": \"SEMESTER\", \"relationship_type\": \"OFFERED_IN\"},\n",
    "        #SEMESTER (can be excluded as this is exception for module info?)\n",
    "        ('module_entities', 'staff_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"STAFF\", \"relationship_type\": \"TAUGHT_BY\"},\n",
    "        ('staff_entities', 'department_entities'): {\"from_type\": \"STAFF\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"EMPLOYED_UNDER\"},\n",
    "        ('department_entities', 'faculty_entities'): {\"from_type\": \"DEPARTMENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"PART_OF\"},\n",
    "        ('job_entities', 'faculty_entities'): {\"from_type\": \"DEPARTMENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"PART_OF\"},\n",
    "        ('major_entities', 'degree_entities'): {\"from_type\": \"MAJOR\", \"to_type\": \"DEGREE\", \"relationship_type\": \"IS_UNDER\"},\n",
    "        ('job_entities', 'skill_entities'): {\"from_type\": \"JOB\", \"to_type\": \"SKILL\", \"relationship_type\": \"REQUIRES\"},\n",
    "        ('module_entities', 'skill_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"SKILL\", \"relationship_type\": \"SKILL_TAUGHT\"},\n",
    "        ## ADDED\n",
    "        ('university_entities', 'degree_entities'): {\"from_type\": \"UNIVERSTITY\", \"to_type\": \"DEGREE\", \"relationship_type\": \"OFFERS\"},\n",
    "\n",
    "    }\n",
    "\n",
    "    # Extract entities function \n",
    "    def extract_entities(csv_file_path):\n",
    "        def parse_entity(x, entity_type):\n",
    "            # Handle dictionary strings e.g. \n",
    "            if isinstance(x, str) and x.startswith('{') and x.endswith('}'):\n",
    "                return ast.literal_eval(x)  # Convert to dictionary\n",
    "            # Handle already existing list \n",
    "            elif isinstance(x, list):\n",
    "                # return [str(item).strip() for item in flatten_list(x)]  \n",
    "                return [(str(item).strip(), entity_type) for item in flatten_list(x)]\n",
    "            # Handle list strings\n",
    "            elif isinstance(x, str) and x.startswith('[') and x.endswith(']'):\n",
    "                try:\n",
    "                    parsed_list = ast.literal_eval(x)  # Convert string representation of list to actual list\n",
    "                    # return [str(item).strip() for item in flatten_list(parsed_list)]\n",
    "                    return [(str(item).strip(), entity_type) for item in flatten_list(parsed_list)]\n",
    "                except (ValueError, SyntaxError):\n",
    "                    # return [x.strip()] \n",
    "                    return [(x.strip(), entity_type)]\n",
    "                \n",
    "            # Handle comma-separated strings\n",
    "            # NEED TO REVISE THIS AS SOME VALUES HAVE COMMA IN ITSELF E.G. COLLEGE OF HUMANITIES, ARTS & SOCIAL SCIENCES \n",
    "            elif pd.notna(x):\n",
    "                # return [str(item).strip() for item in str(x).split(',')]\n",
    "                # return [x.strip()]\n",
    "                return [(x.strip(), entity_type)]\n",
    "            \n",
    "            # Return an empty list for NaN or other invalid entries\n",
    "            return []\n",
    "        \n",
    "        # Helper function to flatten nested lists\n",
    "        def flatten_list(nested_list):\n",
    "            flat_list = []\n",
    "            for i in nested_list:\n",
    "                if isinstance(i, list):\n",
    "                    flat_list.extend(flatten_list(i))\n",
    "                else:\n",
    "                    flat_list.append(i)\n",
    "            return flat_list\n",
    "\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Extract unique skills from the 'Skills' column in a separate CSV\n",
    "        skills_csv_file_path = '../../backend/data/07 - Jobs and relevant skillset (linkedin).csv'\n",
    "        df_skills = pd.read_csv(skills_csv_file_path)\n",
    "        unique_skills = []\n",
    "        \n",
    "        if 'Skills' in df_skills.columns:\n",
    "            # Modified skills parsing\n",
    "            skills_list = []\n",
    "            for skill_text in df_skills[\"Skills\"].dropna():\n",
    "                # Handle the case where skills are comma-separated\n",
    "                if isinstance(skill_text, str):\n",
    "                    # Remove any square brackets if present\n",
    "                    skill_text = skill_text.strip('[]')\n",
    "                    # Split by comma and clean up each skill\n",
    "                    skills = [skill.strip().strip('\"\\'') for skill in skill_text.split(',')]\n",
    "                    skills_list.extend(skills)\n",
    "            \n",
    "            # Clean up skills and remove duplicates\n",
    "            unique_skills = list(set([re.sub(r'\\s\\(.*\\)', '', skill) for skill in skills_list if skill]))\n",
    "\n",
    "            # remove bracketed abbreviations from skills and the space before it\n",
    "            unique_skills = [re.sub(r'\\s\\(.*\\)', '', skill) for skill in unique_skills]\n",
    "\n",
    "            # remove 'Microsoft ' substring before skills\n",
    "            unique_skills = [re.sub(r'Microsoft\\s', '', skill) for skill in unique_skills]\n",
    "\n",
    "        # Function to extract skills using PhraseMatcher\n",
    "        def extract_skills(text):\n",
    "            if not isinstance(text, str):\n",
    "                return []  # Return an empty list if the input is not a valid string\n",
    "            \n",
    "            doc = nlp(text)\n",
    "            skills = [] \n",
    "\n",
    "            # extract skill entities\n",
    "            for skill in unique_skills:\n",
    "                # create a regex pattern with word boundaries around the job title\n",
    "                pattern = r\"\\b\" + re.escape(skill) + r\"\\b\"\n",
    "    \n",
    "                # search for the job title in the text (case-insensitive)\n",
    "                if re.search(pattern, text, re.IGNORECASE):\n",
    "                    skills.append(skill)\n",
    "\n",
    "            return skills\n",
    "\n",
    "        # Function to extract staff names\n",
    "        def extract_staff_names(text):\n",
    "            if isinstance(text, str):\n",
    "                doc = nlp(text)\n",
    "                staff = []\n",
    "\n",
    "                # Regex pattern to capture staff names with titles like 'Prof', 'Dr', 'Lecturer', 'Tutor'\n",
    "                staff_pattern = re.compile(r'\\b(Prof|Professor|Dr|Lecturer|Tutor|Instructor)\\s*[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?', re.IGNORECASE)\n",
    "                \n",
    "                for ent in doc.ents:\n",
    "                    match = staff_pattern.search(ent.text)\n",
    "                    if match:\n",
    "                        staff_name = match.group(0)\n",
    "\n",
    "                        # Exclude unwanted phrases that are falsely detected as staff names\n",
    "                        if not any(word in staff_name.lower() for word in ['tutorial', 'attendance', 'assignment', 'participation', 'ratios', 'draft', 'profile']):\n",
    "                            staff.append(staff_name.strip())\n",
    "\n",
    "                # Remove duplicates in staff\n",
    "                return list(set(staff))  \n",
    "            \n",
    "            return [] \n",
    "\n",
    "        # Extract semester entities\n",
    "        semester_cols = ['semester_01', 'semester_02', 'semester_03', 'semester_04']\n",
    "        if all(col in df.columns for col in semester_cols):\n",
    "            df['semester_entities'] = df.apply(lambda row: [(col, 'SEMESTER') for col in semester_cols if row[col] == 1], axis=1)\n",
    "\n",
    "        # Extract entities using appropriate functions \n",
    "        for col in target_cols:\n",
    "            if col in df.columns:\n",
    "                # new_entity_col = new_entity_cols[col]     \n",
    "                new_entity_col, entity_type = new_entity_cols.get(col, (col, 'UNKNOWN'))  # Default entity type as 'UNKNOWN'  \n",
    "\n",
    "                # If the column is description or message, we apply special extraction\n",
    "                if col in ['description']:\n",
    "                    # df['skill_entities'] = df[col].apply(lambda text: extract_skills(text))\n",
    "                    df['skill_entities'] = df[col].apply(lambda text: [(skill, 'SKILL') for skill in extract_skills(text)])\n",
    "\n",
    "                elif col in ['description', 'message']:\n",
    "                    # df['skill_entities'] = df[col].apply(lambda text: extract_skills(text))\n",
    "                    # df['staff_entities'] = df[col].apply(lambda text: extract_staff_names(text))\n",
    "                    df['skill_entities'] = df[col].apply(lambda text: [(skill, 'SKILL') for skill in extract_skills(text)])\n",
    "                    df['staff_entities'] = df[col].apply(lambda text: [(staff, 'STAFF') for staff in extract_staff_names(text)])\n",
    "\n",
    "                else:\n",
    "                    # Create the new column with extracted entities, using the helper function\n",
    "                    # df[new_entity_col] = df[col].apply(parse_entity)\n",
    "                    df[new_entity_col] = df[col].apply(lambda x: parse_entity(x, entity_type))\n",
    "\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Extract relationships function \n",
    "    def create_dynamic_relationship(df, from_type, from_id_col, to_type, to_id_col, relationship_type, output_col):\n",
    "        # List to store formatted relationship dictionaries for each row\n",
    "        relationship_column = []\n",
    "\n",
    "        # Iterate through each row of the DataFrame\n",
    "        for _, row in df.iterrows():\n",
    "            # Extract the from_id and to_id values from the specified columns\n",
    "            # from_ids = row[from_id_col] if isinstance(row[from_id_col], list) else [row[from_id_col]]\n",
    "            # to_ids = row[to_id_col] if isinstance(row[to_id_col], list) else [row[to_id_col]]\n",
    "            from_ids = [entity[0] for entity in row[from_id_col] if isinstance(entity, tuple)] if isinstance(row[from_id_col], list) else [row[from_id_col]]\n",
    "            to_ids = [entity[0] for entity in row[to_id_col] if isinstance(entity, tuple)] if isinstance(row[to_id_col], list) else [row[to_id_col]]\n",
    "\n",
    "            # Create a list of dictionaries\n",
    "            relationship_dict = [\n",
    "                {\n",
    "                    \"from_type\": from_type,\n",
    "                    \"from_id\": from_id,\n",
    "                    \"to_type\": to_type,\n",
    "                    \"to_id\": to_id,\n",
    "                    \"type\": relationship_type\n",
    "                }\n",
    "                for from_id in from_ids if pd.notna(from_id)\n",
    "                for to_id in to_ids if pd.notna(to_id)  # Only include non-NaN to_id values\n",
    "            ]\n",
    "\n",
    "            # Append the relationship dictionary or an empty list if no valid to_id found\n",
    "            relationship_column.append(relationship_dict if relationship_dict else [])\n",
    "\n",
    "        # Add the relationships as a new column to the DataFrame\n",
    "        df[output_col] = relationship_column\n",
    "        \n",
    "        # Return the updated DataFrame with the new relationships column\n",
    "        return df\n",
    "    \n",
    "    # Step 1: Extract Entities \n",
    "    df = extract_entities(csv_file_path)\n",
    "\n",
    "    # Step 2: Extract Relationships based on predefined mappings \n",
    "    for key, relationship_info in relationship_mappings.items():\n",
    "        if len(key) == 3:\n",
    "            from_col, to_col, rel_key = key\n",
    "        elif len(key) == 2:\n",
    "            from_col, to_col = key\n",
    "            rel_key = ''  # Set rel_key as an empty string or any default value as needed\n",
    "\n",
    "        if from_col in df.columns and to_col in df.columns:\n",
    "            output_col = f\"{from_col}_to_{to_col}_{relationship_info['relationship_type'].lower()}_relationship\"\n",
    "            df = create_dynamic_relationship(\n",
    "                df,\n",
    "                relationship_info['from_type'],\n",
    "                from_col,\n",
    "                relationship_info['to_type'],\n",
    "                to_col,\n",
    "                relationship_info['relationship_type'],\n",
    "                output_col\n",
    "            )\n",
    "\n",
    "    # Combine all relationship columns into one\n",
    "    relationship_columns = [col for col in df.columns if '_relationship' in col]\n",
    "    df['relationships'] = df[relationship_columns].apply(lambda row: [item for sublist in row if isinstance(sublist, list) for item in sublist], axis=1)\n",
    "\n",
    "    # Drop the individual relationship columns if no longer needed\n",
    "    df = df.drop(columns=relationship_columns)\n",
    "\n",
    "    # Step 3: Output final df\n",
    "    return df\n",
    "\n",
    "\n",
    "# Extract from existing cleaned datasets \n",
    "csv_file_path = '../../backend/data/00 - mock_student_data.csv'\n",
    "# csv_file_path = '../../backend/data/01 - mock_module_info.csv'\n",
    "# csv_file_path = '../../backend/data/02 - mock_department_list.csv'\n",
    "# csv_file_path = '../../backend/data/03 - mock_staff_info.csv'\n",
    "# csv_file_path = '../../backend/data/04 - mock_module_reviews.csv'\n",
    "# csv_file_path = '../../backend/data/05 - mock_venue_info.csv'\n",
    "# csv_file_path = '../../backend/data/06 - nus_undergraduate_programmes.csv'\n",
    "# csv_file_path = '../../backend/data/07 - Jobs abd relevant skillset (linkedin).csv'\n",
    "# csv_file_path = '../../backend/data/08 - jobs_and_tech (ONET).csv'\n",
    "# csv_file_path = '../../backend/data/09 - jobs_and_skills (ONET).csv'\n",
    "# csv_file_path = '../../backend/data/10 - Graduate Employment Survey.csv'\n",
    "\n",
    "\n",
    "df = extract_entities_rs(csv_file_path)\n",
    "print(df.head())\n",
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ze Ming's draft\n",
    "\n",
    "- argument for relationship extraction should be just the df that is returned from the entity extraction function + the new csv file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(csv_file_path):\n",
    "\n",
    "    # Predefined entity columns and their corresponding new column names\n",
    "    target_cols = ['Degree', 'Major', 'Module', 'module_code', 'Skills', 'Staff', 'Modules_Completed', 'department', 'faculty', \n",
    "                   'Employee Name', 'Department', 'Modules Taught', 'Title', 'Job Title', 'Tech Skills', 'School', 'University']  # Add any other columns you want to check for\n",
    "    \n",
    "    new_entity_cols = {\n",
    "        'Degree': 'degree_entities',\n",
    "        'Major': 'major_entities',\n",
    "        'Module': 'module_entities',\n",
    "        'module_code': 'module_entities',\n",
    "        'Skills': 'skills_entities',\n",
    "        'Tech Skills': 'skills_entities',\n",
    "        'Staff': 'staff_entities',\n",
    "        'Modules_Completed': 'modules_completed_entities',\n",
    "        'department': 'department_entities', \n",
    "        'faculty': 'faculty_entities',\n",
    "        'School': 'faculty_entities',\n",
    "        'Employee Name': 'staff_entities', \n",
    "        'Department': 'department_entities', \n",
    "        'Modules Taught': 'module_entities',\n",
    "        'Title': 'job_entities',\n",
    "        'Job Title': 'job_entities',\n",
    "        'University': 'university_entities'\n",
    "    }\n",
    "\n",
    "\n",
    "    def parse_entity(x):\n",
    "        # Handle dictionary strings\n",
    "        if isinstance(x, str) and x.startswith('{') and x.endswith('}'):\n",
    "            return ast.literal_eval(x)  # Convert to dictionary\n",
    "        \n",
    "        # Handle list strings\n",
    "        elif isinstance(x, str) and x.startswith('[') and x.endswith(']'):\n",
    "            return [f\"'{str(item).strip()}'\" for item in ast.literal_eval(x)]\n",
    "        \n",
    "        # Handle comma-separated strings\n",
    "        elif pd.notna(x):\n",
    "            return [f\"'{str(item).strip()}'\" for item in str(x).split(',')]\n",
    "        \n",
    "        # Return an empty list for NaN or other invalid entries\n",
    "        return []\n",
    "\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Process each specified entity column\n",
    "    for col in target_cols:\n",
    "        if col in df.columns:\n",
    "            # Determine the new column name based on new_col_names dictionary if provided\n",
    "            new_entity_col = new_entity_cols[col]\n",
    "            \n",
    "            # Create the new column with extracted entities, using the helper function\n",
    "            df[new_entity_col] = df[col].apply(parse_entity)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dynamic_relationship(df, from_type, from_id_col, to_type, to_id_col, relationship_type, output_col):\n",
    "    # List to store formatted relationship dictionaries for each row\n",
    "    relationship_column = []\n",
    "\n",
    "    # Iterate through each row of the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Extract the `from_id` and `to_id` values from the specified columns\n",
    "        from_ids = row[from_id_col] if isinstance(row[from_id_col], list) else [row[from_id_col]]\n",
    "        to_ids = row[to_id_col] if isinstance(row[to_id_col], list) else [row[to_id_col]]\n",
    "\n",
    "        # Create a list of dictionaries for each `to_id`\n",
    "        relationship_dict = [\n",
    "            {\n",
    "                \"from_type\": from_type,\n",
    "                \"from_id\": from_id,\n",
    "                \"to_type\": to_type,\n",
    "                \"to_id\": to_id,\n",
    "                \"type\": relationship_type\n",
    "            }\n",
    "            for from_id in from_ids if pd.notna(from_id)\n",
    "            for to_id in to_ids if pd.notna(to_id)  # Only include non-NaN `to_id` values\n",
    "        ]\n",
    "\n",
    "        # Append the relationship dictionary or an empty list if no valid `to_id` found\n",
    "        relationship_column.append(relationship_dict if relationship_dict else [])\n",
    "\n",
    "    # Add the relationships as a new column to the DataFrame\n",
    "    df[output_col] = relationship_column\n",
    "    \n",
    "    # Return the updated DataFrame with the new relationships column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chloe's draft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_entities(csv_file_path, entity_cols, new_col_names=None):\n",
    "#     df = pd.read_csv(csv_file_path)    \n",
    "#     # Process each specified entity column\n",
    "#     for col in entity_cols:\n",
    "#         if col in df.columns:\n",
    "#             # Determine the new column name based on new_col_names dictionary if provided\n",
    "#             new_col_name = new_col_names[col]\n",
    "#             # new_col_name = new_col_names.get(col, f'{col}_entities') if new_col_names else f'{col}_entities'\n",
    "            \n",
    "#             # Create the new column with extracted entities and rename it as needed if its not in a list \n",
    "#             df[new_col_name] = df[col].apply(\n",
    "#                 lambda x: x if isinstance(x, list) else [item.strip() for item in str(x).split(',')] if pd.notna(x) else []\n",
    "#             )\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Student_Name Matric_Number       NRIC  Year  \\\n",
      "0      Tracy Lewis     A0216920B  XXXXX506Z     1   \n",
      "1    Andrew Holden     A0225069H  XXXXX799Z     3   \n",
      "2  Phillip Bullock     A0228204E  XXXXX194Z     1   \n",
      "3    Stephen Owens     A0263298Z  XXXXX790Z     1   \n",
      "4   Valerie Rivera     A0200778Y  XXXXX150Z     3   \n",
      "\n",
      "                           Faculties                    Major Second Major  \\\n",
      "0                NUS Business School  Business Administration          NaN   \n",
      "1          YST Conservatory of Music                    Music          NaN   \n",
      "2  College of Design and Engineering   Electrical Engineering          NaN   \n",
      "3                          Dentistry                Dentistry          NaN   \n",
      "4                          Computing       Business Analytics          NaN   \n",
      "\n",
      "                                   Modules_Completed  \\\n",
      "0  ['ACC1701B', 'DMB1202ACC', 'DMB1201MKT', 'MNO1...   \n",
      "1  ['CFA1111A', 'MUA1190', 'MUA2109', 'MUA1172', ...   \n",
      "2  ['ME1102', 'BN1111', 'PF1103', 'CN1101A', 'ID1...   \n",
      "3                                                 []   \n",
      "4  ['CS3236R', 'CS1010', 'CP3209', 'CS1010R', 'IS...   \n",
      "\n",
      "                                              Grades     student_entities  \\\n",
      "0  {'ACC1701B': 'B', 'DMB1202ACC': 'A', 'DMB1201M...      ['Tracy Lewis']   \n",
      "1  {'CFA1111A': 'F', 'MUA1190': 'A', 'MUA2109': '...    ['Andrew Holden']   \n",
      "2  {'ME1102': 'F', 'BN1111': 'B-', 'PF1103': 'C+'...  ['Phillip Bullock']   \n",
      "3                                                 {}    ['Stephen Owens']   \n",
      "4  {'CS3236R': 'A+', 'CS1010': 'A+', 'CP3209': 'A...   ['Valerie Rivera']   \n",
      "\n",
      "                                     module_entities  \\\n",
      "0  ['ACC1701B', 'DMB1202ACC', 'DMB1201MKT', 'MNO1...   \n",
      "1  ['CFA1111A', 'MUA1190', 'MUA2109', 'MUA1172', ...   \n",
      "2  ['ME1102', 'BN1111', 'PF1103', 'CN1101A', 'ID1...   \n",
      "3                                                 []   \n",
      "4  ['CS3236R', 'CS1010', 'CP3209', 'CS1010R', 'IS...   \n",
      "\n",
      "                                      grade_entities  \\\n",
      "0  {'ACC1701B': 'B', 'DMB1202ACC': 'A', 'DMB1201M...   \n",
      "1  {'CFA1111A': 'F', 'MUA1190': 'A', 'MUA2109': '...   \n",
      "2  {'ME1102': 'F', 'BN1111': 'B-', 'PF1103': 'C+'...   \n",
      "3                                                 {}   \n",
      "4  {'CS3236R': 'A+', 'CS1010': 'A+', 'CP3209': 'A...   \n",
      "\n",
      "                        faculty_entities               major_entities  \n",
      "0                ['NUS Business School']  ['Business Administration']  \n",
      "1          ['YST Conservatory of Music']                    ['Music']  \n",
      "2  ['College of Design and Engineering']   ['Electrical Engineering']  \n",
      "3                          ['Dentistry']                ['Dentistry']  \n",
      "4                          ['Computing']       ['Business Analytics']  \n"
     ]
    }
   ],
   "source": [
    "# 00 - mock_student_data.csv\n",
    "csv_file_path = '../../backend/data/00 - mock_student_data.csv'\n",
    "entity_cols = ['Student_Name', 'Modules_Completed', 'Grades', 'Faculties', 'Major']\n",
    "new_col_names = {'Student_Name': 'student_entities', 'Modules_Completed': 'module_entities', 'Grades': 'grade_entities', 'Faculties': 'faculty_entities', 'Major': 'major_entities'}\n",
    "\n",
    "df = extract_entities(csv_file_path, entity_cols, new_col_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  department_id                    department  \\\n",
      "0     NUSDP0001    NUS Medicine Dean's Office   \n",
      "1     NUSDP0002                  Architecture   \n",
      "2     NUSDP0003                    Accounting   \n",
      "3     NUSDP0004  Communications and New Media   \n",
      "4     NUSDP0005                       History   \n",
      "\n",
      "                             faculty             department_entities  \\\n",
      "0       Yong Loo Lin Sch of Medicine    [NUS Medicine Dean's Office]   \n",
      "1  College of Design and Engineering                  [Architecture]   \n",
      "2                NUS Business School                    [Accounting]   \n",
      "3            Arts and Social Science  [Communications and New Media]   \n",
      "4            Arts and Social Science                       [History]   \n",
      "\n",
      "                      faculty_entities  \n",
      "0       [Yong Loo Lin Sch of Medicine]  \n",
      "1  [College of Design and Engineering]  \n",
      "2                [NUS Business School]  \n",
      "3            [Arts and Social Science]  \n",
      "4            [Arts and Social Science]  \n"
     ]
    }
   ],
   "source": [
    "# 02 - mock_department_list\n",
    "csv_file_path = '../../backend/data/02 - mock_department_list.csv'\n",
    "entity_cols = ['department', 'faculty']\n",
    "new_col_names = {'department': 'department_entities', 'faculty': 'faculty_entities'}\n",
    "\n",
    "df = extract_entities(csv_file_path, entity_cols, new_col_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Employee ID          staff_entities       NRIC                   DOB  \\\n",
      "0  NUSPF12345  Marin Sergio Hernandez  XXXXX479A  1983-02-23T00:00:00Z   \n",
      "1  NUSPF12346         Kathryn Cordova  XXXXX815A  1985-09-02T00:00:00Z   \n",
      "2  NUSPF12347         Barbara Sanchez  XXXXX777A  1971-07-30T00:00:00Z   \n",
      "3  NUSPF12348             Bryce Lucas  XXXXX610A  1973-07-20T00:00:00Z   \n",
      "4  NUSPF12349          Judith Camacho  XXXXX629A  1991-11-16T00:00:00Z   \n",
      "\n",
      "                    DOJ                  department_entities module_entities  \\\n",
      "0  2009-10-31T00:00:00Z  Electrical and Computer Engineering         CEG5003   \n",
      "1  2009-06-07T00:00:00Z  Civil and Environmental Engineering         ESE2102   \n",
      "2  2008-05-09T00:00:00Z          Centre for Language Studies       LAT4201HM   \n",
      "3  2002-01-17T00:00:00Z                    BIZ Dean's Office      DMB1203MNO   \n",
      "4  2000-02-13T00:00:00Z                            Economics        EC4401HM   \n",
      "\n",
      "             staff_entities                    department_entities  \\\n",
      "0  [Marin Sergio Hernandez]  [Electrical and Computer Engineering]   \n",
      "1         [Kathryn Cordova]  [Civil and Environmental Engineering]   \n",
      "2         [Barbara Sanchez]          [Centre for Language Studies]   \n",
      "3             [Bryce Lucas]                    [BIZ Dean's Office]   \n",
      "4          [Judith Camacho]                            [Economics]   \n",
      "\n",
      "  module_entities  \n",
      "0       [CEG5003]  \n",
      "1       [ESE2102]  \n",
      "2     [LAT4201HM]  \n",
      "3    [DMB1203MNO]  \n",
      "4      [EC4401HM]  \n"
     ]
    }
   ],
   "source": [
    "# 03 - mock_staff_info\n",
    "csv_file_path = '../../backend/data/03 - mock_staff_info.csv'\n",
    "entity_cols = ['Employee Name', 'Department', 'Modules Taught']\n",
    "new_col_names = {'Employee Name': 'staff_entities', 'Department': 'department_entities', 'Modules Taught': 'module_entities'}\n",
    "\n",
    "df = extract_entities(csv_file_path, entity_cols, new_col_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05 - mock_venue_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       degree_entities  \\\n",
      "0  Bachelor of Business Administration   \n",
      "1  Bachelor of Business Administration   \n",
      "2  Bachelor of Business Administration   \n",
      "3  Bachelor of Business Administration   \n",
      "4  Bachelor of Business Administration   \n",
      "\n",
      "                            major_entities  \\\n",
      "0               Applied Business Analytics   \n",
      "1                       Business Economics   \n",
      "2                                  Finance   \n",
      "3          Innovation and Entrepreneurship   \n",
      "4  Leadership and Human Capital Management   \n",
      "\n",
      "                         degree_entities  \\\n",
      "0  [Bachelor of Business Administration]   \n",
      "1  [Bachelor of Business Administration]   \n",
      "2  [Bachelor of Business Administration]   \n",
      "3  [Bachelor of Business Administration]   \n",
      "4  [Bachelor of Business Administration]   \n",
      "\n",
      "                              major_entities  \n",
      "0               [Applied Business Analytics]  \n",
      "1                       [Business Economics]  \n",
      "2                                  [Finance]  \n",
      "3          [Innovation and Entrepreneurship]  \n",
      "4  [Leadership and Human Capital Management]  \n"
     ]
    }
   ],
   "source": [
    "# 06 - nus_undergraduate_programmes.csv\n",
    "csv_file_path = '../../backend/data/06 - nus_undergraduate_programmes.csv'\n",
    "entity_cols = ['Degree', 'Major']\n",
    "new_col_names = {'Degree': 'degree_entities', 'Major': 'major_entities'}\n",
    "\n",
    "df = extract_entities(csv_file_path, entity_cols, new_col_names)\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
