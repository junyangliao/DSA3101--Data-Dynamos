{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity and Relationship Extractions function\n",
    "\n",
    "- argument to be just the original csv file path\n",
    "- if any column names is in the list of column names then we carry out the functions below\n",
    "- one function for entity extraction (exlcuding module info and review csv)\n",
    "- one function for relationship extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Student_Name Matric_Number       NRIC  Year  \\\n",
      "0      Tracy Lewis     A0216920B  XXXXX506Z     1   \n",
      "1    Andrew Holden     A0225069H  XXXXX799Z     3   \n",
      "2  Phillip Bullock     A0228204E  XXXXX194Z     1   \n",
      "3    Stephen Owens     A0263298Z  XXXXX790Z     1   \n",
      "4   Valerie Rivera     A0200778Y  XXXXX150Z     3   \n",
      "\n",
      "                           Faculties                    Major Second Major  \\\n",
      "0                NUS Business School  Business Administration          NaN   \n",
      "1          YST Conservatory of Music                    Music          NaN   \n",
      "2  College of Design and Engineering   Electrical Engineering          NaN   \n",
      "3                          Dentistry                Dentistry          NaN   \n",
      "4                          Computing       Business Analytics          NaN   \n",
      "\n",
      "                                   Modules_Completed  \\\n",
      "0  ['ACC1701B', 'DMB1202ACC', 'DMB1201MKT', 'MNO1...   \n",
      "1  ['CFA1111A', 'MUA1190', 'MUA2109', 'MUA1172', ...   \n",
      "2  ['ME1102', 'BN1111', 'PF1103', 'CN1101A', 'ID1...   \n",
      "3                                                 []   \n",
      "4  ['CS3236R', 'CS1010', 'CP3209', 'CS1010R', 'IS...   \n",
      "\n",
      "                                              Grades  \\\n",
      "0  {'ACC1701B': 'B', 'DMB1202ACC': 'A', 'DMB1201M...   \n",
      "1  {'CFA1111A': 'F', 'MUA1190': 'A', 'MUA2109': '...   \n",
      "2  {'ME1102': 'F', 'BN1111': 'B-', 'PF1103': 'C+'...   \n",
      "3                                                 {}   \n",
      "4  {'CS3236R': 'A+', 'CS1010': 'A+', 'CP3209': 'A...   \n",
      "\n",
      "                major_entities  \\\n",
      "0  ['Business Administration']   \n",
      "1                    ['Music']   \n",
      "2   ['Electrical Engineering']   \n",
      "3                ['Dentistry']   \n",
      "4       ['Business Analytics']   \n",
      "\n",
      "                          modules_completed_entities  \n",
      "0  ['ACC1701B', 'DMB1202ACC', 'DMB1201MKT', 'MNO1...  \n",
      "1  ['CFA1111A', 'MUA1190', 'MUA2109', 'MUA1172', ...  \n",
      "2  ['ME1102', 'BN1111', 'PF1103', 'CN1101A', 'ID1...  \n",
      "3                                                 []  \n",
      "4  ['CS3236R', 'CS1010', 'CP3209', 'CS1010R', 'IS...  \n"
     ]
    }
   ],
   "source": [
    "def extract_entities_rs(csv_file_path): \n",
    "\n",
    "    # Predefined entity columns and their corresponding new column names\n",
    "    target_cols = ['Degree', 'Major', 'Module', 'module_code', 'Skills', 'Staff', 'Modules_Completed', 'department', 'faculty', \n",
    "                'Employee Name', 'Department', 'Modules Taught', 'Title', 'Job Title', 'Tech Skills', 'School', 'University']  # Add any other columns you want to check for\n",
    "    \n",
    "    new_entity_cols = {\n",
    "        'Degree': 'degree_entities',\n",
    "        'Major': 'major_entities',\n",
    "        'Module': 'module_entities',\n",
    "        'module_code': 'module_entities',\n",
    "        'prerequisite': 'prerequisite_entities',\n",
    "        'preclusion': 'preclusion_entities',\n",
    "        'Skills': 'skill_entities',\n",
    "        'Tech Skills': 'skill_entities',\n",
    "        'Staff': 'staff_entities',\n",
    "        'Modules_Completed': 'modules_completed_entities',\n",
    "        'department': 'department_entities', \n",
    "        'faculty': 'faculty_entities',\n",
    "        'School': 'faculty_entities',\n",
    "        'Employee Name': 'staff_entities', \n",
    "        'Department': 'department_entities', \n",
    "        'Modules Taught': 'module_entities',\n",
    "        'Title': 'job_entities',\n",
    "        'Job Title': 'job_entities',\n",
    "        'University': 'university_entities'\n",
    "    }\n",
    "\n",
    "    # Relationship mappings\n",
    "    relationship_mappings = {\n",
    "        ('student_entities', 'faculty_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"STUDYING_UNDER\"},\n",
    "        ('student_entities', 'major_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"MAJOR\", \"relationship_type\": \"MAJOR_IN\"},\n",
    "        ('student_entities', 'module_entities'): {\"from_type\": \"STUDENT\", \"to_type\": \"MODULE\", \"relationship_type\": \"COMPLETED\"},\n",
    "        ('module_entities', 'department_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"BELONGS_TO\"},\n",
    "        ('module_entities', 'prerequisite_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"MUST_HAVE_TAKEN_ONE_OF\"},\n",
    "        ('module_entities', 'preclusion_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"MUST_NOT_HAVE_TAKEN_ONE_OF\"},\n",
    "        #SEMESTER (can be excluded as this is exception for module info?)\n",
    "        ('module_entities', 'staff_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"STAFF\", \"relationship_type\": \"TAUGHT_BY\"},\n",
    "        ('staff_entities', 'department_entities'): {\"from_type\": \"STAFF\", \"to_type\": \"DEPARTMENT\", \"relationship_type\": \"EMPLOYED_UNDER\"},\n",
    "        ('department_entities', 'faculty_entities'): {\"from_type\": \"DEPARTMENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"PART_OF\"},\n",
    "        ('job_entities', 'faculty_entities'): {\"from_type\": \"DEPARTMENT\", \"to_type\": \"FACULTY\", \"relationship_type\": \"PART_OF\"},\n",
    "        ('major_entities', 'degree_entities'): {\"from_type\": \"MAJOR\", \"to_type\": \"DEGREE\", \"relationship_type\": \"IS_UNDER\"},\n",
    "        ('job_entities', 'skill_entities'): {\"from_type\": \"JOB\", \"to_type\": \"SKILL\", \"relationship_type\": \"REQUIRES\"},\n",
    "        ('module_entities', 'skill_entities'): {\"from_type\": \"MODULE\", \"to_type\": \"SKILL\", \"relationship_type\": \"SKILL_TAUGHT\"},\n",
    "        ## ADDED\n",
    "        ('university_entities', 'degree_entities'): {\"from_type\": \"UNIVERSTITY\", \"to_type\": \"DEGREE\", \"relationship_type\": \"OFFERS\"},\n",
    "\n",
    "    }\n",
    "\n",
    "    # Extract entities function \n",
    "    def extract_entities(csv_file_path):\n",
    "        def parse_entity(x):\n",
    "            # Handle dictionary strings\n",
    "            if isinstance(x, str) and x.startswith('{') and x.endswith('}'):\n",
    "                return ast.literal_eval(x)  # Convert to dictionary\n",
    "            \n",
    "            # Handle list strings\n",
    "            elif isinstance(x, str) and x.startswith('[') and x.endswith(']'):\n",
    "                return [f\"'{str(item).strip()}'\" for item in ast.literal_eval(x)]\n",
    "            \n",
    "            # Handle comma-separated strings\n",
    "            elif pd.notna(x):\n",
    "                return [f\"'{str(item).strip()}'\" for item in str(x).split(',')]\n",
    "            \n",
    "            # Return an empty list for NaN or other invalid entries\n",
    "            return []\n",
    "\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Process each specified entity column\n",
    "        for col in target_cols:\n",
    "            if col in df.columns:\n",
    "                # Determine the new column name based on new_col_names dictionary if provided\n",
    "                new_entity_col = new_entity_cols[col]\n",
    "                \n",
    "                # Create the new column with extracted entities, using the helper function\n",
    "                df[new_entity_col] = df[col].apply(parse_entity)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    # Extract relationships function \n",
    "    def create_dynamic_relationship(df, from_type, from_id_col, to_type, to_id_col, relationship_type, output_col):\n",
    "        # List to store formatted relationship dictionaries for each row\n",
    "        relationship_column = []\n",
    "\n",
    "        # Iterate through each row of the DataFrame\n",
    "        for _, row in df.iterrows():\n",
    "            # Extract the `from_id` and `to_id` values from the specified columns\n",
    "            from_ids = row[from_id_col] if isinstance(row[from_id_col], list) else [row[from_id_col]]\n",
    "            to_ids = row[to_id_col] if isinstance(row[to_id_col], list) else [row[to_id_col]]\n",
    "\n",
    "            # Create a list of dictionaries for each `to_id`\n",
    "            relationship_dict = [\n",
    "                {\n",
    "                    \"from_type\": from_type,\n",
    "                    \"from_id\": from_id,\n",
    "                    \"to_type\": to_type,\n",
    "                    \"to_id\": to_id,\n",
    "                    \"type\": relationship_type\n",
    "                }\n",
    "                for from_id in from_ids if pd.notna(from_id)\n",
    "                for to_id in to_ids if pd.notna(to_id)  # Only include non-NaN `to_id` values\n",
    "            ]\n",
    "\n",
    "            # Append the relationship dictionary or an empty list if no valid `to_id` found\n",
    "            relationship_column.append(relationship_dict if relationship_dict else [])\n",
    "\n",
    "        # Add the relationships as a new column to the DataFrame\n",
    "        df[output_col] = relationship_column\n",
    "        \n",
    "        # Return the updated DataFrame with the new relationships column\n",
    "        return df\n",
    "    \n",
    "    # Call extract entities function \n",
    "    df = extract_entities(csv_file_path)\n",
    "\n",
    "    # Create relationships based on the mappings\n",
    "    for (from_col, to_col), relationship_info in relationship_mappings.items():\n",
    "        if from_col in df.columns and to_col in df.columns:\n",
    "            output_col = f\"{from_col}_to_{to_col}_relationship\"\n",
    "            df = create_dynamic_relationship(\n",
    "                df, \n",
    "                relationship_info['from_type'], \n",
    "                from_col, \n",
    "                relationship_info['to_type'], \n",
    "                to_col, \n",
    "                relationship_info['relationship_type'], \n",
    "                output_col\n",
    "            )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# 00 - mock_student_data.csv\n",
    "csv_file_path = '../../backend/data/00 - mock_student_data.csv'\n",
    "df = extract_entities_rs(csv_file_path)\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ze Ming's draft\n",
    "\n",
    "- argument for relationship extraction should be just the df that is returned from the entity extraction function + the new csv file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(csv_file_path):\n",
    "\n",
    "    # Predefined entity columns and their corresponding new column names\n",
    "    target_cols = ['Degree', 'Major', 'Module', 'module_code', 'Skills', 'Staff', 'Modules_Completed', 'department', 'faculty', \n",
    "                   'Employee Name', 'Department', 'Modules Taught', 'Title', 'Job Title', 'Tech Skills', 'School', 'University']  # Add any other columns you want to check for\n",
    "    \n",
    "    new_entity_cols = {\n",
    "        'Degree': 'degree_entities',\n",
    "        'Major': 'major_entities',\n",
    "        'Module': 'module_entities',\n",
    "        'module_code': 'module_entities',\n",
    "        'Skills': 'skills_entities',\n",
    "        'Tech Skills': 'skills_entities',\n",
    "        'Staff': 'staff_entities',\n",
    "        'Modules_Completed': 'modules_completed_entities',\n",
    "        'department': 'department_entities', \n",
    "        'faculty': 'faculty_entities',\n",
    "        'School': 'faculty_entities',\n",
    "        'Employee Name': 'staff_entities', \n",
    "        'Department': 'department_entities', \n",
    "        'Modules Taught': 'module_entities',\n",
    "        'Title': 'job_entities',\n",
    "        'Job Title': 'job_entities',\n",
    "        'University': 'university_entities'\n",
    "    }\n",
    "\n",
    "\n",
    "    def parse_entity(x):\n",
    "        # Handle dictionary strings\n",
    "        if isinstance(x, str) and x.startswith('{') and x.endswith('}'):\n",
    "            return ast.literal_eval(x)  # Convert to dictionary\n",
    "        \n",
    "        # Handle list strings\n",
    "        elif isinstance(x, str) and x.startswith('[') and x.endswith(']'):\n",
    "            return [f\"'{str(item).strip()}'\" for item in ast.literal_eval(x)]\n",
    "        \n",
    "        # Handle comma-separated strings\n",
    "        elif pd.notna(x):\n",
    "            return [f\"'{str(item).strip()}'\" for item in str(x).split(',')]\n",
    "        \n",
    "        # Return an empty list for NaN or other invalid entries\n",
    "        return []\n",
    "\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Process each specified entity column\n",
    "    for col in target_cols:\n",
    "        if col in df.columns:\n",
    "            # Determine the new column name based on new_col_names dictionary if provided\n",
    "            new_entity_col = new_entity_cols[col]\n",
    "            \n",
    "            # Create the new column with extracted entities, using the helper function\n",
    "            df[new_entity_col] = df[col].apply(parse_entity)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dynamic_relationship(df, from_type, from_id_col, to_type, to_id_col, relationship_type, output_col):\n",
    "    # List to store formatted relationship dictionaries for each row\n",
    "    relationship_column = []\n",
    "\n",
    "    # Iterate through each row of the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Extract the `from_id` and `to_id` values from the specified columns\n",
    "        from_ids = row[from_id_col] if isinstance(row[from_id_col], list) else [row[from_id_col]]\n",
    "        to_ids = row[to_id_col] if isinstance(row[to_id_col], list) else [row[to_id_col]]\n",
    "\n",
    "        # Create a list of dictionaries for each `to_id`\n",
    "        relationship_dict = [\n",
    "            {\n",
    "                \"from_type\": from_type,\n",
    "                \"from_id\": from_id,\n",
    "                \"to_type\": to_type,\n",
    "                \"to_id\": to_id,\n",
    "                \"type\": relationship_type\n",
    "            }\n",
    "            for from_id in from_ids if pd.notna(from_id)\n",
    "            for to_id in to_ids if pd.notna(to_id)  # Only include non-NaN `to_id` values\n",
    "        ]\n",
    "\n",
    "        # Append the relationship dictionary or an empty list if no valid `to_id` found\n",
    "        relationship_column.append(relationship_dict if relationship_dict else [])\n",
    "\n",
    "    # Add the relationships as a new column to the DataFrame\n",
    "    df[output_col] = relationship_column\n",
    "    \n",
    "    # Return the updated DataFrame with the new relationships column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chloe's draft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_entities(csv_file_path, entity_cols, new_col_names=None):\n",
    "#     df = pd.read_csv(csv_file_path)    \n",
    "#     # Process each specified entity column\n",
    "#     for col in entity_cols:\n",
    "#         if col in df.columns:\n",
    "#             # Determine the new column name based on new_col_names dictionary if provided\n",
    "#             new_col_name = new_col_names[col]\n",
    "#             # new_col_name = new_col_names.get(col, f'{col}_entities') if new_col_names else f'{col}_entities'\n",
    "            \n",
    "#             # Create the new column with extracted entities and rename it as needed if its not in a list \n",
    "#             df[new_col_name] = df[col].apply(\n",
    "#                 lambda x: x if isinstance(x, list) else [item.strip() for item in str(x).split(',')] if pd.notna(x) else []\n",
    "#             )\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Student_Name Matric_Number       NRIC  Year  \\\n",
      "0      Tracy Lewis     A0216920B  XXXXX506Z     1   \n",
      "1    Andrew Holden     A0225069H  XXXXX799Z     3   \n",
      "2  Phillip Bullock     A0228204E  XXXXX194Z     1   \n",
      "3    Stephen Owens     A0263298Z  XXXXX790Z     1   \n",
      "4   Valerie Rivera     A0200778Y  XXXXX150Z     3   \n",
      "\n",
      "                           Faculties                    Major Second Major  \\\n",
      "0                NUS Business School  Business Administration          NaN   \n",
      "1          YST Conservatory of Music                    Music          NaN   \n",
      "2  College of Design and Engineering   Electrical Engineering          NaN   \n",
      "3                          Dentistry                Dentistry          NaN   \n",
      "4                          Computing       Business Analytics          NaN   \n",
      "\n",
      "                                   Modules_Completed  \\\n",
      "0  ['ACC1701B', 'DMB1202ACC', 'DMB1201MKT', 'MNO1...   \n",
      "1  ['CFA1111A', 'MUA1190', 'MUA2109', 'MUA1172', ...   \n",
      "2  ['ME1102', 'BN1111', 'PF1103', 'CN1101A', 'ID1...   \n",
      "3                                                 []   \n",
      "4  ['CS3236R', 'CS1010', 'CP3209', 'CS1010R', 'IS...   \n",
      "\n",
      "                                              Grades     student_entities  \\\n",
      "0  {'ACC1701B': 'B', 'DMB1202ACC': 'A', 'DMB1201M...      ['Tracy Lewis']   \n",
      "1  {'CFA1111A': 'F', 'MUA1190': 'A', 'MUA2109': '...    ['Andrew Holden']   \n",
      "2  {'ME1102': 'F', 'BN1111': 'B-', 'PF1103': 'C+'...  ['Phillip Bullock']   \n",
      "3                                                 {}    ['Stephen Owens']   \n",
      "4  {'CS3236R': 'A+', 'CS1010': 'A+', 'CP3209': 'A...   ['Valerie Rivera']   \n",
      "\n",
      "                                     module_entities  \\\n",
      "0  ['ACC1701B', 'DMB1202ACC', 'DMB1201MKT', 'MNO1...   \n",
      "1  ['CFA1111A', 'MUA1190', 'MUA2109', 'MUA1172', ...   \n",
      "2  ['ME1102', 'BN1111', 'PF1103', 'CN1101A', 'ID1...   \n",
      "3                                                 []   \n",
      "4  ['CS3236R', 'CS1010', 'CP3209', 'CS1010R', 'IS...   \n",
      "\n",
      "                                      grade_entities  \\\n",
      "0  {'ACC1701B': 'B', 'DMB1202ACC': 'A', 'DMB1201M...   \n",
      "1  {'CFA1111A': 'F', 'MUA1190': 'A', 'MUA2109': '...   \n",
      "2  {'ME1102': 'F', 'BN1111': 'B-', 'PF1103': 'C+'...   \n",
      "3                                                 {}   \n",
      "4  {'CS3236R': 'A+', 'CS1010': 'A+', 'CP3209': 'A...   \n",
      "\n",
      "                        faculty_entities               major_entities  \n",
      "0                ['NUS Business School']  ['Business Administration']  \n",
      "1          ['YST Conservatory of Music']                    ['Music']  \n",
      "2  ['College of Design and Engineering']   ['Electrical Engineering']  \n",
      "3                          ['Dentistry']                ['Dentistry']  \n",
      "4                          ['Computing']       ['Business Analytics']  \n"
     ]
    }
   ],
   "source": [
    "# 00 - mock_student_data.csv\n",
    "csv_file_path = '../../backend/data/00 - mock_student_data.csv'\n",
    "entity_cols = ['Student_Name', 'Modules_Completed', 'Grades', 'Faculties', 'Major']\n",
    "new_col_names = {'Student_Name': 'student_entities', 'Modules_Completed': 'module_entities', 'Grades': 'grade_entities', 'Faculties': 'faculty_entities', 'Major': 'major_entities'}\n",
    "\n",
    "df = extract_entities(csv_file_path, entity_cols, new_col_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  department_id                    department  \\\n",
      "0     NUSDP0001    NUS Medicine Dean's Office   \n",
      "1     NUSDP0002                  Architecture   \n",
      "2     NUSDP0003                    Accounting   \n",
      "3     NUSDP0004  Communications and New Media   \n",
      "4     NUSDP0005                       History   \n",
      "\n",
      "                             faculty             department_entities  \\\n",
      "0       Yong Loo Lin Sch of Medicine    [NUS Medicine Dean's Office]   \n",
      "1  College of Design and Engineering                  [Architecture]   \n",
      "2                NUS Business School                    [Accounting]   \n",
      "3            Arts and Social Science  [Communications and New Media]   \n",
      "4            Arts and Social Science                       [History]   \n",
      "\n",
      "                      faculty_entities  \n",
      "0       [Yong Loo Lin Sch of Medicine]  \n",
      "1  [College of Design and Engineering]  \n",
      "2                [NUS Business School]  \n",
      "3            [Arts and Social Science]  \n",
      "4            [Arts and Social Science]  \n"
     ]
    }
   ],
   "source": [
    "# 02 - mock_department_list\n",
    "csv_file_path = '../../backend/data/02 - mock_department_list.csv'\n",
    "entity_cols = ['department', 'faculty']\n",
    "new_col_names = {'department': 'department_entities', 'faculty': 'faculty_entities'}\n",
    "\n",
    "df = extract_entities(csv_file_path, entity_cols, new_col_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Employee ID          staff_entities       NRIC                   DOB  \\\n",
      "0  NUSPF12345  Marin Sergio Hernandez  XXXXX479A  1983-02-23T00:00:00Z   \n",
      "1  NUSPF12346         Kathryn Cordova  XXXXX815A  1985-09-02T00:00:00Z   \n",
      "2  NUSPF12347         Barbara Sanchez  XXXXX777A  1971-07-30T00:00:00Z   \n",
      "3  NUSPF12348             Bryce Lucas  XXXXX610A  1973-07-20T00:00:00Z   \n",
      "4  NUSPF12349          Judith Camacho  XXXXX629A  1991-11-16T00:00:00Z   \n",
      "\n",
      "                    DOJ                  department_entities module_entities  \\\n",
      "0  2009-10-31T00:00:00Z  Electrical and Computer Engineering         CEG5003   \n",
      "1  2009-06-07T00:00:00Z  Civil and Environmental Engineering         ESE2102   \n",
      "2  2008-05-09T00:00:00Z          Centre for Language Studies       LAT4201HM   \n",
      "3  2002-01-17T00:00:00Z                    BIZ Dean's Office      DMB1203MNO   \n",
      "4  2000-02-13T00:00:00Z                            Economics        EC4401HM   \n",
      "\n",
      "             staff_entities                    department_entities  \\\n",
      "0  [Marin Sergio Hernandez]  [Electrical and Computer Engineering]   \n",
      "1         [Kathryn Cordova]  [Civil and Environmental Engineering]   \n",
      "2         [Barbara Sanchez]          [Centre for Language Studies]   \n",
      "3             [Bryce Lucas]                    [BIZ Dean's Office]   \n",
      "4          [Judith Camacho]                            [Economics]   \n",
      "\n",
      "  module_entities  \n",
      "0       [CEG5003]  \n",
      "1       [ESE2102]  \n",
      "2     [LAT4201HM]  \n",
      "3    [DMB1203MNO]  \n",
      "4      [EC4401HM]  \n"
     ]
    }
   ],
   "source": [
    "# 03 - mock_staff_info\n",
    "csv_file_path = '../../backend/data/03 - mock_staff_info.csv'\n",
    "entity_cols = ['Employee Name', 'Department', 'Modules Taught']\n",
    "new_col_names = {'Employee Name': 'staff_entities', 'Department': 'department_entities', 'Modules Taught': 'module_entities'}\n",
    "\n",
    "df = extract_entities(csv_file_path, entity_cols, new_col_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05 - mock_venue_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       degree_entities  \\\n",
      "0  Bachelor of Business Administration   \n",
      "1  Bachelor of Business Administration   \n",
      "2  Bachelor of Business Administration   \n",
      "3  Bachelor of Business Administration   \n",
      "4  Bachelor of Business Administration   \n",
      "\n",
      "                            major_entities  \\\n",
      "0               Applied Business Analytics   \n",
      "1                       Business Economics   \n",
      "2                                  Finance   \n",
      "3          Innovation and Entrepreneurship   \n",
      "4  Leadership and Human Capital Management   \n",
      "\n",
      "                         degree_entities  \\\n",
      "0  [Bachelor of Business Administration]   \n",
      "1  [Bachelor of Business Administration]   \n",
      "2  [Bachelor of Business Administration]   \n",
      "3  [Bachelor of Business Administration]   \n",
      "4  [Bachelor of Business Administration]   \n",
      "\n",
      "                              major_entities  \n",
      "0               [Applied Business Analytics]  \n",
      "1                       [Business Economics]  \n",
      "2                                  [Finance]  \n",
      "3          [Innovation and Entrepreneurship]  \n",
      "4  [Leadership and Human Capital Management]  \n"
     ]
    }
   ],
   "source": [
    "# 06 - nus_undergraduate_programmes.csv\n",
    "csv_file_path = '../../backend/data/06 - nus_undergraduate_programmes.csv'\n",
    "entity_cols = ['Degree', 'Major']\n",
    "new_col_names = {'Degree': 'degree_entities', 'Major': 'major_entities'}\n",
    "\n",
    "df = extract_entities(csv_file_path, entity_cols, new_col_names)\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
